{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a37b849d-d8e3-4c31-b353-ec0c72f83224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 01:59:32,397 - INFO - Starting dataset creation...\n",
      "2025-01-19 01:59:32,397 - INFO - Processing region 1/1: 10.7449, 92.5\n",
      "2025-01-19 01:59:40,451 - ERROR - Error fetching green cover data for 10.7449, 92.5: module 'osmnx' has no attribute 'geometries_from_point'\n",
      "2025-01-19 01:59:40,452 - ERROR - Error fetching land usage data for 10.7449, 92.5: module 'osmnx' has no attribute 'geometries_from_point'\n",
      "2025-01-19 01:59:40,453 - ERROR - Error fetching water coverage data for 10.7449, 92.5: module 'osmnx' has no attribute 'geometries_from_place'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from typing import Dict, List, Optional, Union\n",
    "import time\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define API keys and endpoints\n",
    "OPENWEATHER_API_KEY = \"9cdf050abe7b42592268c0bf78c0195a\"\n",
    "GBIF_API_BASE = \"https://api.gbif.org/v1/occurrence/search\"\n",
    "\n",
    "# Add rate limiting parameters\n",
    "REQUEST_DELAY = 1  # Delay between API requests in seconds\n",
    "\n",
    "def fetch_climate_data(lat: float, lon: float) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Fetch climate data using OpenWeatherMap API with improved precipitation handling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = f\"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        time.sleep(REQUEST_DELAY)\n",
    "        \n",
    "        # Improved precipitation handling\n",
    "        precipitation = 0\n",
    "        if \"rain\" in data:\n",
    "            precipitation = data[\"rain\"].get(\"1h\", 0) or data[\"rain\"].get(\"3h\", 0)\n",
    "        elif \"snow\" in data:\n",
    "            precipitation = data[\"snow\"].get(\"1h\", 0) or data[\"snow\"].get(\"3h\", 0)\n",
    "        \n",
    "        return {\n",
    "            \"temperature\": data[\"main\"][\"temp\"],\n",
    "            \"precipitation\": precipitation,\n",
    "            \"humidity\": data[\"main\"][\"humidity\"],\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching climate data for {lat}, {lon}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def fetch_biodiversity_data(lat: float, lon: float) -> int:\n",
    "    \"\"\"\n",
    "    Fetch biodiversity data using GBIF API with improved species counting.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        params = {\n",
    "            \"decimalLatitude\": f\"{lat-0.5},{lat+0.5}\",\n",
    "            \"decimalLongitude\": f\"{lon-0.5},{lon+0.5}\",\n",
    "            \"limit\": 300,  # Increased limit\n",
    "            \"hasCoordinate\": True,\n",
    "            \"hasGeospatialIssue\": False\n",
    "        }\n",
    "        response = requests.get(GBIF_API_BASE, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        time.sleep(REQUEST_DELAY)\n",
    "        \n",
    "        # Count unique species\n",
    "        species_set = set()\n",
    "        for record in data.get(\"results\", []):\n",
    "            if record.get(\"species\"):\n",
    "                species_set.add(record[\"species\"])\n",
    "        \n",
    "        return len(species_set)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching biodiversity data for {lat}, {lon}: {str(e)}\")\n",
    "        return 0\n",
    "\n",
    "def fetch_green_cover_data(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fetch green cover data with improved NDVI calculation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a larger area for analysis\n",
    "        dist = 1000  # increased from 500 to 1000 meters\n",
    "        tags = {\n",
    "            'landuse': ['forest', 'grass', 'park', 'meadow', 'recreation_ground'],\n",
    "            'natural': ['wood', 'grassland', 'heath']\n",
    "        }\n",
    "        \n",
    "        area = ox.geometries_from_point((lat, lon), tags=tags, dist=dist)\n",
    "        \n",
    "        if not area.empty:\n",
    "            total_area = np.pi * (dist ** 2)  # Total circular area\n",
    "            green_area = area.geometry.area.sum()\n",
    "            ndvi_proxy = green_area / total_area\n",
    "            return max(min(ndvi_proxy, 1), 0)\n",
    "        return 0.0\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching green cover data for {lat}, {lon}: {str(e)}\")\n",
    "        return 0.0\n",
    "\n",
    "def fetch_land_usage_data(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fetch land usage data with improved urban density calculation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dist = 1000  # Analysis radius in meters\n",
    "        \n",
    "        # Get both buildings and roads\n",
    "        building_tags = {'building': True}\n",
    "        buildings = ox.geometries_from_point((lat, lon), tags=building_tags, dist=dist)\n",
    "        \n",
    "        graph = ox.graph_from_point((lat, lon), dist=dist, network_type='all')\n",
    "        \n",
    "        total_area = np.pi * (dist ** 2)\n",
    "        building_area = buildings.geometry.area.sum() if not buildings.empty else 0\n",
    "        road_length = sum(d['length'] for u, v, d in graph.edges(data=True))\n",
    "        \n",
    "        # Combine building coverage and road density for urban usage metric\n",
    "        urban_density = (building_area / total_area) + (road_length / (dist * 2 * np.pi))\n",
    "        return max(min(urban_density, 1), 0)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching land usage data for {lat}, {lon}: {str(e)}\")\n",
    "        return 0.0\n",
    "\n",
    "def fetch_water_coverage_data(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fetch water coverage data with improved calculation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dist = 1000  # Analysis radius in meters\n",
    "        water_tags = {\n",
    "            'natural': ['water', 'wetland'],\n",
    "            'water': True,\n",
    "            'waterway': ['river', 'canal', 'stream']\n",
    "        }\n",
    "        \n",
    "        water_features = ox.geometries_from_place((lat, lon), tags=water_tags, dist=dist)\n",
    "        \n",
    "        if not water_features.empty:\n",
    "            total_area = np.pi * (dist ** 2)\n",
    "            water_area = water_features.geometry.area.sum()\n",
    "            water_coverage = water_area / total_area\n",
    "            return max(min(water_coverage, 1), 0)\n",
    "        return 0.0\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching water coverage data for {lat}, {lon}: {str(e)}\")\n",
    "        return 0.0\n",
    "\n",
    "def generate_risk_score(\n",
    "    ndvi: float,\n",
    "    species_richness: int,\n",
    "    urban_land_usage: float,\n",
    "    water_coverage: float,\n",
    "    land_use_type: str\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate a risk score based on environmental factors.\n",
    "    \n",
    "    Args:\n",
    "        ndvi (float): Normalized Difference Vegetation Index\n",
    "        species_richness (int): Number of species in area\n",
    "        urban_land_usage (float): Urban density metric\n",
    "        water_coverage (float): Water coverage ratio\n",
    "        land_use_type (str): Type of land use\n",
    "        \n",
    "    Returns:\n",
    "        float: Risk score between 0 and 1\n",
    "    \"\"\"\n",
    "    land_use_weight = {\n",
    "        \"green-based use\": 0.1,\n",
    "        \"agricultural use\": 0.2,\n",
    "        \"urban home-type use\": 0.3,\n",
    "        \"commercial/industrial use\": 0.4\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        risk_score = (\n",
    "            (1 - ndvi) * 0.35 +\n",
    "            (species_richness / 100) * 0.25 +\n",
    "            (urban_land_usage / 100) * 0.25 +\n",
    "            (1 - water_coverage) * 0.15\n",
    "        )\n",
    "        \n",
    "        risk_score *= land_use_weight.get(land_use_type, 0.25)\n",
    "        return min(max(risk_score, 0), 1)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating risk score: {str(e)}\")\n",
    "        return 0.5\n",
    "\n",
    "def create_dataset(\n",
    "    regions: List[Dict[str, float]],\n",
    "    land_use_types: List[str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a labeled dataset across various regions with selected land use types.\n",
    "    \n",
    "    Args:\n",
    "        regions (list): List of dictionaries containing lat/lon coordinates\n",
    "        land_use_types (list): List of land use type strings\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataset containing environmental metrics and risk scores\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    total_regions = len(regions)\n",
    "    \n",
    "    for idx, region in enumerate(regions, 1):\n",
    "        try:\n",
    "            lat, lon = region[\"lat\"], region[\"lon\"]\n",
    "            logger.info(f\"Processing region {idx}/{total_regions}: {lat}, {lon}\")\n",
    "            \n",
    "            climate_data = fetch_climate_data(lat, lon)\n",
    "            biodiversity_data = fetch_biodiversity_data(lat, lon)\n",
    "            green_cover = fetch_green_cover_data(lat, lon)\n",
    "            land_usage = fetch_land_usage_data(lat, lon)\n",
    "            water_coverage = fetch_water_coverage_data(lat, lon)\n",
    "            \n",
    "            if climate_data:\n",
    "                for land_use_type in land_use_types:\n",
    "                    risk_score = generate_risk_score(\n",
    "                        green_cover,\n",
    "                        biodiversity_data,\n",
    "                        land_usage,\n",
    "                        water_coverage,\n",
    "                        land_use_type\n",
    "                    )\n",
    "                    \n",
    "                    data.append({\n",
    "                        \"latitude\": lat,\n",
    "                        \"longitude\": lon,\n",
    "                        \"temperature\": climate_data[\"temperature\"],\n",
    "                        \"precipitation\": climate_data[\"precipitation\"],\n",
    "                        \"humidity\": climate_data[\"humidity\"],\n",
    "                        \"species_richness\": biodiversity_data,\n",
    "                        \"ndvi\": green_cover,\n",
    "                        \"urban_land_usage\": land_usage,\n",
    "                        \"water_coverage\": water_coverage,\n",
    "                        \"land_use_type\": land_use_type,\n",
    "                        \"risk_score\": risk_score,\n",
    "                        # \"timestamp\": datetime.now().isoformat()\n",
    "                    })\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing region {lat}, {lon}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the data collection and analysis.\"\"\"\n",
    "    # Define regions (example coordinates for various landscapes)\n",
    "    regions = [\n",
    "        {\"lat\": 10.7449, \"lon\": 92.5000},  # New York City, USA\n",
    "        # {\"lat\": -33.8688, \"lon\": 151.2093},  # Sydney, Australia\n",
    "        # {\"lat\": 51.5074, \"lon\": -0.1278},   # London, UK\n",
    "        # {\"lat\": -1.286389, \"lon\": 36.817223},  # Nairobi, Kenya\n",
    "        # {\"lat\": 28.6139, \"lon\": 77.2090}    # New Delhi, India\n",
    "    ]\n",
    "\n",
    "    # Define possible land use types\n",
    "    land_use_types = [\n",
    "        \"green-based use\",\n",
    "        \"agricultural use\",\n",
    "        \"urban home-type use\",\n",
    "        \"commercial/industrial use\"\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Create the dataset\n",
    "        logger.info(\"Starting dataset creation...\")\n",
    "        dataset = create_dataset(regions, land_use_types)\n",
    "        \n",
    "        # Save to CSV\n",
    "        # output_filename = f\"urban_planning_risk_dataset_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        # dataset.to_csv(output_filename, index=False)\n",
    "        # logger.info(f\"Dataset successfully created and saved as '{output_filename}'\")\n",
    "        \n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main execution: {str(e)}\")\n",
    "        return None\n",
    "dataset = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c7fa8a9-014c-4ddd-b680-6a3d2fb9ad0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting osmnx\n",
      "  Downloading osmnx-2.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting geopandas>=1.0 (from osmnx)\n",
      "  Downloading geopandas-1.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: networkx>=2.5 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from osmnx) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from osmnx) (1.26.0)\n",
      "Requirement already satisfied: pandas>=1.4 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from osmnx) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.27 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from osmnx) (2.32.3)\n",
      "Collecting shapely>=2.0 (from osmnx)\n",
      "  Downloading shapely-2.0.6-cp311-cp311-win_amd64.whl.metadata (7.2 kB)\n",
      "Collecting pyogrio>=0.7.2 (from geopandas>=1.0->osmnx)\n",
      "  Downloading pyogrio-0.10.0-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from geopandas>=1.0->osmnx) (23.2)\n",
      "Collecting pyproj>=3.3.0 (from geopandas>=1.0->osmnx)\n",
      "  Downloading pyproj-3.7.0-cp311-cp311-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.4->osmnx) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.4->osmnx) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.4->osmnx) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.27->osmnx) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.27->osmnx) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.27->osmnx) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.27->osmnx) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.16.0)\n",
      "Downloading osmnx-2.0.1-py3-none-any.whl (99 kB)\n",
      "Downloading geopandas-1.0.1-py3-none-any.whl (323 kB)\n",
      "Downloading shapely-2.0.6-cp311-cp311-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.4 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.5/1.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.0/1.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading pyogrio-0.10.0-cp311-cp311-win_amd64.whl (16.2 MB)\n",
      "   ---------------------------------------- 0.0/16.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/16.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/16.2 MB 2.5 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.6/16.2 MB 2.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 2.4/16.2 MB 2.9 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 3.1/16.2 MB 3.1 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.9/16.2 MB 3.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 4.7/16.2 MB 3.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 5.8/16.2 MB 3.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 6.6/16.2 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.9/16.2 MB 3.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 9.2/16.2 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.4/16.2 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.4/16.2 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.4/16.2 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.4/16.2 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.4/16.2 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 10.0/16.2 MB 2.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 11.3/16.2 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 12.6/16.2 MB 3.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.6/16.2 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 15.2/16.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.2/16.2 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading pyproj-3.7.0-cp311-cp311-win_amd64.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 2.1/6.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 10.6 MB/s eta 0:00:00\n",
      "Installing collected packages: shapely, pyproj, pyogrio, geopandas, osmnx\n",
      "Successfully installed geopandas-1.0.1 osmnx-2.0.1 pyogrio-0.10.0 pyproj-3.7.0 shapely-2.0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install osmnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f67a9c2f-e125-436d-bad9-4b8c5afb3da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = (28.7975,76.1322)\n",
    "l2 = (11,75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "516446f5-fe13-4f5c-8b84-ca8a3ef29621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_climate_data(lat: float, lon: float) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Fetch climate data using OpenWeatherMap API with 5-day precipitation forecast.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get current weather\n",
    "        current_url = f\"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
    "        current_response = requests.get(current_url)\n",
    "        current_response.raise_for_status()\n",
    "        current_data = current_response.json()\n",
    "        \n",
    "        # Get 5 day forecast with 3-hour steps\n",
    "        forecast_url = f\"https://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
    "        forecast_response = requests.get(forecast_url)\n",
    "        forecast_response.raise_for_status()\n",
    "        forecast_data = forecast_response.json()\n",
    "        \n",
    "        # Calculate average precipitation from forecast\n",
    "        total_precipitation = 0\n",
    "        count = 0\n",
    "        \n",
    "        for item in forecast_data.get('list', []):\n",
    "            # Get precipitation (rain or snow)\n",
    "            rain_amount = item.get('rain', {}).get('3h', 0)\n",
    "            snow_amount = item.get('snow', {}).get('3h', 0)\n",
    "            total_precipitation += rain_amount + snow_amount\n",
    "            count += 1\n",
    "        \n",
    "        # Convert 3-hourly precipitation to daily average\n",
    "        avg_daily_precipitation = (total_precipitation / count) * 8 if count > 0 else 0\n",
    "        # Estimate monthly precipitation (multiply by 30 days)\n",
    "        estimated_monthly_precipitation = avg_daily_precipitation * 30\n",
    "        \n",
    "        return {\n",
    "            \"temperature\": current_data[\"main\"][\"temp\"],\n",
    "            \"precipitation\": estimated_monthly_precipitation,\n",
    "            \"humidity\": current_data[\"main\"][\"humidity\"],\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching climate data for {lat}, {lon}: {str(e)}\")\n",
    "        return None\n",
    "    finally:\n",
    "        time.sleep(REQUEST_DELAY)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80dda3f6-e537-4d73-bc5d-60c199eef250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temperature': 12.27, 'precipitation': 1.7999999999999998, 'humidity': 49}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_climate_data(*l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47914118-5137-4598-9c63-d0fde2e4222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_biodiversity_data(lat: float, lon: float) -> int:\n",
    "    \"\"\"\n",
    "    Fetch biodiversity data using GBIF API with improved species counting.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        params = {\n",
    "            \"decimalLatitude\": f\"{lat-0.5},{lat+0.5}\",\n",
    "            \"decimalLongitude\": f\"{lon-0.5},{lon+0.5}\",\n",
    "            \"limit\": 300,  # Increased limit\n",
    "            \"hasCoordinate\": True,\n",
    "            \"hasGeospatialIssue\": False\n",
    "        }\n",
    "        response = requests.get(GBIF_API_BASE, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        time.sleep(REQUEST_DELAY)\n",
    "        \n",
    "        # Count unique species\n",
    "        species_set = set()\n",
    "        for record in data.get(\"results\", []):\n",
    "            if record.get(\"species\"):\n",
    "                species_set.add(record[\"species\"])\n",
    "        \n",
    "        return len(species_set)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching biodiversity data for {lat}, {lon}: {str(e)}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2af50a8f-e8e6-405d-82b6-ba35e7514bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_biodiversity_data(l[0],l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f44452e4-2716-4880-a3d2-ad3c45ac200b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ee'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mee\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ee'"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def fetch_green_cover_data(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fetch green cover data using Copernicus Global Land Service API.\n",
    "    Uses NDVI (Normalized Difference Vegetation Index) data.\n",
    "    \n",
    "    Args:\n",
    "        lat (float): Latitude\n",
    "        lon (float): Longitude\n",
    "    \n",
    "    Returns:\n",
    "        float: NDVI value between 0 and 1\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Using Copernicus Global Land Service API\n",
    "        base_url = \"https://land.copernicus.vgt.vito.be/REST/TimeSeries/1.0/extract\"\n",
    "        \n",
    "        # Current date and one month ago\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=30)\n",
    "        \n",
    "        params = {\n",
    "            'lat': lat,\n",
    "            'lon': lon,\n",
    "            'startdate': start_date.strftime('%Y-%m-%d'),\n",
    "            'enddate': end_date.strftime('%Y-%m-%d'),\n",
    "            'collection': 'NDVI_V2',\n",
    "            'format': 'json'\n",
    "        }\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0',\n",
    "            'Accept': 'application/json'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(base_url, params=params, headers=headers)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            # Fallback to alternative API: OpenMeteo\n",
    "            return _fetch_green_cover_fallback(lat, lon)\n",
    "            \n",
    "        data = response.json()\n",
    "        ndvi_values = [item['NDVI'] for item in data['results'] if 'NDVI' in item]\n",
    "        \n",
    "        if ndvi_values:\n",
    "            # NDVI values are typically between -1 and 1\n",
    "            # Normalize to 0-1 range\n",
    "            avg_ndvi = np.mean(ndvi_values)\n",
    "            normalized_ndvi = (avg_ndvi + 1) / 2\n",
    "            return max(min(normalized_ndvi, 1), 0)\n",
    "            \n",
    "        return _fetch_green_cover_fallback(lat, lon)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in primary green cover fetch: {str(e)}\")\n",
    "        return _fetch_green_cover_fallback(lat, lon)\n",
    "\n",
    "def _fetch_green_cover_fallback(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fallback method using OpenMeteo API for vegetation data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # OpenMeteo API for soil and vegetation data\n",
    "        url = (f\"https://api.open-meteo.com/v1/forecast?\"\n",
    "               f\"latitude={lat}&longitude={lon}\"\n",
    "               f\"&hourly=soil_moisture_0_1cm,soil_moisture_1_3cm\"\n",
    "               f\"&daily=et0_fao_evapotranspiration\")\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Calculate green cover proxy using soil moisture and evapotranspiration\n",
    "        soil_moisture = np.mean(data['hourly']['soil_moisture_0_1cm'][:24])  # First 24 hours\n",
    "        evapotranspiration = data['daily']['et0_fao_evapotranspiration'][0]  # First day\n",
    "        \n",
    "        # Combine metrics to estimate vegetation cover\n",
    "        # Normalize values based on typical ranges\n",
    "        soil_moisture_norm = min(soil_moisture / 50, 1)  # Typical range 0-50\n",
    "        evapotrans_norm = min(evapotranspiration / 10, 1)  # Typical range 0-10\n",
    "        \n",
    "        # Weight the factors\n",
    "        green_cover = (soil_moisture_norm * 0.6 + evapotrans_norm * 0.4)\n",
    "        \n",
    "        return max(min(green_cover, 1), 0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in fallback green cover fetch: {str(e)}\")\n",
    "        return _fetch_green_cover_last_resort(lat, lon)\n",
    "\n",
    "def _fetch_green_cover_last_resort(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Last resort method using NASA POWER API for vegetation-related data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # NASA POWER API\n",
    "        base_url = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "        \n",
    "        params = {\n",
    "            'parameters': 'T2M,PRECTOT,RH2M',  # Temperature, precipitation, humidity\n",
    "            'community': 'AG',\n",
    "            'longitude': lon,\n",
    "            'latitude': lat,\n",
    "            'start': datetime.now().strftime('%Y%m%d'),\n",
    "            'end': datetime.now().strftime('%Y%m%d'),\n",
    "            'format': 'JSON'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract relevant parameters\n",
    "        temp = float(data['properties']['parameter']['T2M'][datetime.now().strftime('%Y%m%d')])\n",
    "        precip = float(data['properties']['parameter']['PRECTOT'][datetime.now().strftime('%Y%m%d')])\n",
    "        humidity = float(data['properties']['parameter']['RH2M'][datetime.now().strftime('%Y%m%d')])\n",
    "        \n",
    "        # Create a simple vegetation index based on environmental conditions\n",
    "        # This is a rough approximation based on typical conditions favorable for vegetation\n",
    "        temp_factor = max(0, min(1 - abs(temp - 20) / 30, 1))  # Optimal temp around 20°C\n",
    "        precip_factor = min(precip / 10, 1)  # Normalize precipitation (0-10mm)\n",
    "        humidity_factor = humidity / 100  # Humidity is already 0-100\n",
    "        \n",
    "        # Combine factors with weights\n",
    "        green_cover = (temp_factor * 0.3 + precip_factor * 0.4 + humidity_factor * 0.3)\n",
    "        \n",
    "        return max(min(green_cover, 1), 0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in last resort green cover fetch: {str(e)}\")\n",
    "        # Return a reasonable default based on global averages\n",
    "        return 0.3  # Global average vegetation cover is roughly 30%\n",
    "\n",
    "def test_green_cover():\n",
    "    \"\"\"\n",
    "    Test function to demonstrate usage and verify functionality.\n",
    "    \"\"\"\n",
    "    # Test coordinates (example: New Delhi, India)\n",
    "    test_locations = [\n",
    "        # (28.7041, 77.1025, \"New Delhi\"),\n",
    "        # (40.7128, -74.0060, \"New York\"),\n",
    "        # (51.5074, -0.1278, \"London\"),\n",
    "        # (11,75,\"Andaman\"),\n",
    "        # (15,71,\"amazon\"),\n",
    "        (0,75,'antartica')\n",
    "    ]\n",
    "    \n",
    "    for lat, lon, name in test_locations:\n",
    "        try:\n",
    "            green_cover = fetch_green_cover_data(lat, lon)\n",
    "            print(f\"\\nGreen cover index for {name} ({lat}, {lon}): {green_cover:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error testing {name}: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_green_cover()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe22d5-9239-4434-be14-ef93cbf07168",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_green_cover_data(*l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d599fe45-a808-4e20-be06-af6813fa7ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_land_usage_data(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fetch land usage data with improved urban density calculation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dist = 1000  # Analysis radius in meters\n",
    "        \n",
    "        # Get both buildings and roads\n",
    "        building_tags = {'building': True}\n",
    "        buildings = ox.geometries_from_point((lat, lon), tags=building_tags, dist=dist)\n",
    "        \n",
    "        graph = ox.graph_from_point((lat, lon), dist=dist, network_type='all')\n",
    "        \n",
    "        total_area = np.pi * (dist ** 2)\n",
    "        building_area = buildings.geometry.area.sum() if not buildings.empty else 0\n",
    "        road_length = sum(d['length'] for u, v, d in graph.edges(data=True))\n",
    "        \n",
    "        # Combine building coverage and road density for urban usage metric\n",
    "        urban_density = (building_area / total_area) + (road_length / (dist * 2 * np.pi))\n",
    "        return max(min(urban_density, 1), 0)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching land usage data for {lat}, {lon}: {str(e)}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c34b0467-326d-40aa-adb9-653f4290276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 02:00:19,554 - ERROR - Error fetching land usage data for 11, 75: module 'osmnx' has no attribute 'geometries_from_point'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_land_usage_data(*l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f671079-497b-4e74-8f6b-dde7e6a68e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for New York (40.7128, -74.006):\n",
      "Urban Density Index: 0.8148\n",
      "Water Coverage Index: 0.0054\n",
      "\n",
      "Results for London (51.5074, -0.1278):\n",
      "Urban Density Index: 0.8748\n",
      "Water Coverage Index: 0.2895\n",
      "\n",
      "Results for Hong Kong (22.3964, 114.1095):\n",
      "Urban Density Index: 0.3026\n",
      "Water Coverage Index: 0.7727\n",
      "\n",
      "Results for dhanbad (23.7957, 86.4304):\n",
      "Urban Density Index: 0.3067\n",
      "Water Coverage Index: 0.1639\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import Dict, Tuple\n",
    "from shapely.geometry import Polygon, MultiPolygon, LineString\n",
    "from shapely.ops import unary_union\n",
    "import json\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def _get_overpass_data(query: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Helper function to fetch data from Overpass API.\n",
    "    \"\"\"\n",
    "    overpass_url = \"https://overpass-api.de/api/interpreter\"\n",
    "    try:\n",
    "        response = requests.post(overpass_url, data={'data': query})\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Overpass API error: {str(e)}\")\n",
    "        return {'elements': []}\n",
    "\n",
    "def fetch_land_usage_data(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fetch land usage data using Overpass API.\n",
    "    Returns urban density index between 0 and 1.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calculate bounding box (1km radius)\n",
    "        radius = 1000  # meters\n",
    "        deg_radius = radius / 111320  # Convert meters to degrees (approximate)\n",
    "        \n",
    "        # Overpass query for buildings and roads\n",
    "        query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          way[\"building\"](around:{radius},{lat},{lon});\n",
    "          way[\"highway\"](around:{radius},{lat},{lon});\n",
    "        );\n",
    "        out body geom;\n",
    "        \"\"\"\n",
    "        \n",
    "        data = _get_overpass_data(query)\n",
    "        \n",
    "        if not data['elements']:\n",
    "            # Fallback to secondary API\n",
    "            return _fetch_land_usage_fallback(lat, lon)\n",
    "        \n",
    "        # Calculate areas and lengths\n",
    "        total_area = np.pi * (radius ** 2)  # Total circular area in square meters\n",
    "        building_area = 0\n",
    "        road_length = 0\n",
    "        \n",
    "        for element in data['elements']:\n",
    "            if 'geometry' in element:\n",
    "                coords = [(p['lon'], p['lat']) for p in element['geometry']]\n",
    "                if element.get('tags', {}).get('building'):\n",
    "                    # Calculate building area\n",
    "                    if len(coords) >= 3:\n",
    "                        try:\n",
    "                            polygon = Polygon(coords)\n",
    "                            building_area += polygon.area * 111320 * 111320  # Convert to square meters\n",
    "                        except:\n",
    "                            continue\n",
    "                elif element.get('tags', {}).get('highway'):\n",
    "                    # Calculate road length\n",
    "                    if len(coords) >= 2:\n",
    "                        try:\n",
    "                            line = LineString(coords)\n",
    "                            road_length += line.length * 111320  # Convert to meters\n",
    "                        except:\n",
    "                            continue\n",
    "        \n",
    "        # Calculate urban density\n",
    "        building_density = min(building_area / total_area, 0.7)  # Cap at 70%\n",
    "        road_density = min(road_length / (radius * 2 * np.pi), 0.3)  # Cap at 30%\n",
    "        \n",
    "        urban_density = building_density + road_density\n",
    "        return min(max(urban_density, 0), 1)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in primary land usage calculation: {str(e)}\")\n",
    "        return _fetch_land_usage_fallback(lat, lon)\n",
    "\n",
    "def _fetch_land_usage_fallback(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fallback method using OpenStreetMap Nominatim API for land use data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use Nominatim API to get area details\n",
    "        nominatim_url = f\"https://nominatim.openstreetmap.org/reverse?lat={lat}&lon={lon}&format=json&zoom=14\"\n",
    "        headers = {'User-Agent': 'Urban Density Calculator 1.0'}\n",
    "        \n",
    "        response = requests.get(nominatim_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Analyze address components and category\n",
    "        address = data.get('address', {})\n",
    "        category = data.get('category', '')\n",
    "        \n",
    "        # Calculate urban density based on location type\n",
    "        if any(k in address for k in ['city', 'town', 'suburb']):\n",
    "            return 0.8  # Urban area\n",
    "        elif 'village' in address:\n",
    "            return 0.4  # Rural settlement\n",
    "        elif any(k in address for k in ['industrial', 'commercial']):\n",
    "            return 0.9  # Industrial/commercial area\n",
    "        elif any(k in address for k in ['forest', 'park', 'nature_reserve']):\n",
    "            return 0.1  # Natural area\n",
    "        else:\n",
    "            return 0.5  # Default semi-urban\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in fallback land usage calculation: {str(e)}\")\n",
    "        return 0.5  # Default value\n",
    "\n",
    "def fetch_water_coverage_data(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fetch water coverage data using Overpass API.\n",
    "    Returns water coverage ratio between 0 and 1.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calculate bounding box (1km radius)\n",
    "        radius = 1000  # meters\n",
    "        \n",
    "        # Overpass query for water features\n",
    "        query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          way[\"natural\"=\"water\"](around:{radius},{lat},{lon});\n",
    "          way[\"waterway\"](around:{radius},{lat},{lon});\n",
    "          way[\"water\"](around:{radius},{lat},{lon});\n",
    "          way[\"natural\"=\"wetland\"](around:{radius},{lat},{lon});\n",
    "        );\n",
    "        out body geom;\n",
    "        \"\"\"\n",
    "        \n",
    "        data = _get_overpass_data(query)\n",
    "        \n",
    "        if not data['elements']:\n",
    "            # Fallback to secondary API\n",
    "            return _fetch_water_coverage_fallback(lat, lon)\n",
    "        \n",
    "        # Calculate areas\n",
    "        total_area = np.pi * (radius ** 2)  # Total circular area in square meters\n",
    "        water_area = 0\n",
    "        \n",
    "        for element in data['elements']:\n",
    "            if 'geometry' in element:\n",
    "                coords = [(p['lon'], p['lat']) for p in element['geometry']]\n",
    "                if len(coords) >= 3:\n",
    "                    try:\n",
    "                        polygon = Polygon(coords)\n",
    "                        water_area += polygon.area * 111320 * 111320  # Convert to square meters\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        water_coverage = water_area / total_area\n",
    "        return min(max(water_coverage, 0), 1)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in primary water coverage calculation: {str(e)}\")\n",
    "        return _fetch_water_coverage_fallback(lat, lon)\n",
    "\n",
    "def _fetch_water_coverage_fallback(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fallback method using OpenMeteo API for water proximity data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use OpenMeteo API for water-related data\n",
    "        url = f\"https://marine-api.open-meteo.com/v1/marine?latitude={lat}&longitude={lon}&daily=wave_height\"\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'daily' in data and 'wave_height' in data['daily']:\n",
    "            # If wave height data is available, location is near water\n",
    "            return min(max(np.mean(data['daily']['wave_height']) / 2, 0), 1)\n",
    "            \n",
    "        # If no marine data, check for inland water bodies using Nominatim\n",
    "        nominatim_url = f\"https://nominatim.openstreetmap.org/reverse?lat={lat}&lon={lon}&format=json&zoom=14\"\n",
    "        headers = {'User-Agent': 'Water Coverage Calculator 1.0'}\n",
    "        \n",
    "        response = requests.get(nominatim_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Check location type\n",
    "        if any(water_type in str(data).lower() for water_type in ['lake', 'river', 'sea', 'ocean', 'bay', 'wetland']):\n",
    "            return 0.7  # Significant water presence\n",
    "        return 0.1  # Minimal water presence\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in fallback water coverage calculation: {str(e)}\")\n",
    "        return 0.1  # Default low water coverage\n",
    "\n",
    "def test_coverage_calculations():\n",
    "    \"\"\"\n",
    "    Test function to demonstrate usage of both functions.\n",
    "    \"\"\"\n",
    "    test_locations = [\n",
    "        (40.7128, -74.0060, \"New York\"),  # New York\n",
    "        (51.5074, -0.1278, \"London\"),    # London\n",
    "        (22.3964, 114.1095, \"Hong Kong\"), # Hong Kong\n",
    "        (23.7957,86.4304, \"dhanbad\")    # Sydney\n",
    "    ]\n",
    "    \n",
    "    for lat, lon, name in test_locations:\n",
    "        try:\n",
    "            land_usage = fetch_land_usage_data(lat, lon)\n",
    "            water_coverage = fetch_water_coverage_data(lat, lon)\n",
    "            \n",
    "            print(f\"\\nResults for {name} ({lat}, {lon}):\")\n",
    "            print(f\"Urban Density Index: {land_usage:.4f}\")\n",
    "            print(f\"Water Coverage Index: {water_coverage:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error testing {name}: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_coverage_calculations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba25ff01-5b87-449c-b606-3a74e842359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 02:00:34,054 - INFO - Analyzing Yellowstone, USA (North America)\n",
      "2025-01-19 02:00:35,744 - ERROR - Error fetching green cover data for 44.428, -110.5885: module 'osmnx' has no attribute 'geometries_from_point'\n",
      "2025-01-19 02:00:43,422 - INFO - Analyzing Amazon Rainforest, Brazil (South America)\n",
      "2025-01-19 02:00:45,254 - ERROR - Error fetching green cover data for -3.4653, -62.2159: module 'osmnx' has no attribute 'geometries_from_point'\n",
      "2025-01-19 02:00:54,938 - INFO - Analyzing Black Forest, Germany (Europe)\n",
      "2025-01-19 02:00:56,685 - ERROR - Error fetching green cover data for 47.8044, 8.1735: module 'osmnx' has no attribute 'geometries_from_point'\n",
      "2025-01-19 02:01:04,593 - INFO - Analyzing Serengeti, Tanzania (Africa)\n",
      "2025-01-19 02:01:06,475 - ERROR - Error fetching green cover data for -2.154, 34.6857: module 'osmnx' has no attribute 'geometries_from_point'\n",
      "2025-01-19 02:01:18,031 - ERROR - Error in fallback water coverage calculation: 400 Client Error: Bad Request for url: https://marine-api.open-meteo.com/v1/marine?latitude=-2.154&longitude=34.6857&daily=wave_height\n",
      "2025-01-19 02:01:18,033 - INFO - Analyzing Western Ghats, India (Asia)\n",
      "2025-01-19 02:01:19,699 - ERROR - Error fetching green cover data for 10.7449, 76.7827: module 'osmnx' has no attribute 'geometries_from_point'\n",
      "2025-01-19 02:01:28,392 - INFO - Analyzing Great Barrier Reef Coast, Australia (Oceania)\n",
      "2025-01-19 02:01:30,258 - ERROR - Error fetching green cover data for -16.2864, 145.6845: module 'osmnx' has no attribute 'geometries_from_point'\n",
      "2025-01-19 02:01:44,217 - ERROR - Error in fallback water coverage calculation: 400 Client Error: Bad Request for url: https://marine-api.open-meteo.com/v1/marine?latitude=-16.2864&longitude=145.6845&daily=wave_height\n",
      "2025-01-19 02:01:44,219 - INFO - Analyzing Antarctic Peninsula (Antarctica)\n",
      "2025-01-19 02:01:46,024 - ERROR - Error fetching green cover data for -64.2314, -56.7242: module 'osmnx' has no attribute 'geometries_from_point'\n",
      "2025-01-19 02:01:56,759 - ERROR - Error in fallback water coverage calculation: 400 Client Error: Bad Request for url: https://marine-api.open-meteo.com/v1/marine?latitude=-64.2314&longitude=-56.7242&daily=wave_height\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Biodiversity Risk Analysis by Continental Location and Development Scenario\n",
      "Analysis Date (UTC): 2025-01-18 20:31:56\n",
      "\n",
      "Risk Score Scale: 0 (Lowest Risk) to 1 (Highest Risk)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "North America Analysis:\n",
      "\n",
      "Location: Yellowstone, USA (44.4280, -110.5885)\n",
      "Development Scenario: Natural Reserve\n",
      "Risk Score: 0.0667\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 86\n",
      "  - Urban Density: 0.3000\n",
      "  - Water Coverage: 0.3272\n",
      "  - Temperature: -16.2°C\n",
      "  - Precipitation: 1.8mm\n",
      "\n",
      "Location: Yellowstone, USA (44.4280, -110.5885)\n",
      "Development Scenario: Agricultural Zone\n",
      "Risk Score: 0.1333\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 86\n",
      "  - Urban Density: 0.3000\n",
      "  - Water Coverage: 0.3272\n",
      "  - Temperature: -16.2°C\n",
      "  - Precipitation: 1.8mm\n",
      "\n",
      "Location: Yellowstone, USA (44.4280, -110.5885)\n",
      "Development Scenario: Residential Area\n",
      "Risk Score: 0.2000\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 86\n",
      "  - Urban Density: 0.3000\n",
      "  - Water Coverage: 0.3272\n",
      "  - Temperature: -16.2°C\n",
      "  - Precipitation: 1.8mm\n",
      "\n",
      "Location: Yellowstone, USA (44.4280, -110.5885)\n",
      "Development Scenario: Industrial Zone\n",
      "Risk Score: 0.2667\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 86\n",
      "  - Urban Density: 0.3000\n",
      "  - Water Coverage: 0.3272\n",
      "  - Temperature: -16.2°C\n",
      "  - Precipitation: 1.8mm\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "South America Analysis:\n",
      "\n",
      "Location: Amazon Rainforest, Brazil (-3.4653, -62.2159)\n",
      "Development Scenario: Natural Reserve\n",
      "Risk Score: 0.0785\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 117\n",
      "  - Urban Density: 0.8000\n",
      "  - Water Coverage: 0.0630\n",
      "  - Temperature: 30.6°C\n",
      "  - Precipitation: 228.5mm\n",
      "\n",
      "Location: Amazon Rainforest, Brazil (-3.4653, -62.2159)\n",
      "Development Scenario: Agricultural Zone\n",
      "Risk Score: 0.1570\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 117\n",
      "  - Urban Density: 0.8000\n",
      "  - Water Coverage: 0.0630\n",
      "  - Temperature: 30.6°C\n",
      "  - Precipitation: 228.5mm\n",
      "\n",
      "Location: Amazon Rainforest, Brazil (-3.4653, -62.2159)\n",
      "Development Scenario: Residential Area\n",
      "Risk Score: 0.2355\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 117\n",
      "  - Urban Density: 0.8000\n",
      "  - Water Coverage: 0.0630\n",
      "  - Temperature: 30.6°C\n",
      "  - Precipitation: 228.5mm\n",
      "\n",
      "Location: Amazon Rainforest, Brazil (-3.4653, -62.2159)\n",
      "Development Scenario: Industrial Zone\n",
      "Risk Score: 0.3140\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 117\n",
      "  - Urban Density: 0.8000\n",
      "  - Water Coverage: 0.0630\n",
      "  - Temperature: 30.6°C\n",
      "  - Precipitation: 228.5mm\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Europe Analysis:\n",
      "\n",
      "Location: Black Forest, Germany (47.8044, 8.1735)\n",
      "Development Scenario: Natural Reserve\n",
      "Risk Score: 0.0678\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 131\n",
      "  - Urban Density: 0.3045\n",
      "  - Water Coverage: 1.0000\n",
      "  - Temperature: -3.9°C\n",
      "  - Precipitation: 42.5mm\n",
      "\n",
      "Location: Black Forest, Germany (47.8044, 8.1735)\n",
      "Development Scenario: Agricultural Zone\n",
      "Risk Score: 0.1357\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 131\n",
      "  - Urban Density: 0.3045\n",
      "  - Water Coverage: 1.0000\n",
      "  - Temperature: -3.9°C\n",
      "  - Precipitation: 42.5mm\n",
      "\n",
      "Location: Black Forest, Germany (47.8044, 8.1735)\n",
      "Development Scenario: Residential Area\n",
      "Risk Score: 0.2035\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 131\n",
      "  - Urban Density: 0.3045\n",
      "  - Water Coverage: 1.0000\n",
      "  - Temperature: -3.9°C\n",
      "  - Precipitation: 42.5mm\n",
      "\n",
      "Location: Black Forest, Germany (47.8044, 8.1735)\n",
      "Development Scenario: Industrial Zone\n",
      "Risk Score: 0.2713\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 131\n",
      "  - Urban Density: 0.3045\n",
      "  - Water Coverage: 1.0000\n",
      "  - Temperature: -3.9°C\n",
      "  - Precipitation: 42.5mm\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Africa Analysis:\n",
      "\n",
      "Location: Serengeti, Tanzania (-2.1540, 34.6857)\n",
      "Development Scenario: Natural Reserve\n",
      "Risk Score: 0.0818\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 133\n",
      "  - Urban Density: 0.3124\n",
      "  - Water Coverage: 0.1000\n",
      "  - Temperature: 20.6°C\n",
      "  - Precipitation: 99.1mm\n",
      "\n",
      "Location: Serengeti, Tanzania (-2.1540, 34.6857)\n",
      "Development Scenario: Agricultural Zone\n",
      "Risk Score: 0.1637\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 133\n",
      "  - Urban Density: 0.3124\n",
      "  - Water Coverage: 0.1000\n",
      "  - Temperature: 20.6°C\n",
      "  - Precipitation: 99.1mm\n",
      "\n",
      "Location: Serengeti, Tanzania (-2.1540, 34.6857)\n",
      "Development Scenario: Residential Area\n",
      "Risk Score: 0.2455\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 133\n",
      "  - Urban Density: 0.3124\n",
      "  - Water Coverage: 0.1000\n",
      "  - Temperature: 20.6°C\n",
      "  - Precipitation: 99.1mm\n",
      "\n",
      "Location: Serengeti, Tanzania (-2.1540, 34.6857)\n",
      "Development Scenario: Industrial Zone\n",
      "Risk Score: 0.3273\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 133\n",
      "  - Urban Density: 0.3124\n",
      "  - Water Coverage: 0.1000\n",
      "  - Temperature: 20.6°C\n",
      "  - Precipitation: 99.1mm\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Asia Analysis:\n",
      "\n",
      "Location: Western Ghats, India (10.7449, 76.7827)\n",
      "Development Scenario: Natural Reserve\n",
      "Risk Score: 0.0868\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 174\n",
      "  - Urban Density: 0.3000\n",
      "  - Water Coverage: 0.4509\n",
      "  - Temperature: 25.2°C\n",
      "  - Precipitation: 35.6mm\n",
      "\n",
      "Location: Western Ghats, India (10.7449, 76.7827)\n",
      "Development Scenario: Agricultural Zone\n",
      "Risk Score: 0.1736\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 174\n",
      "  - Urban Density: 0.3000\n",
      "  - Water Coverage: 0.4509\n",
      "  - Temperature: 25.2°C\n",
      "  - Precipitation: 35.6mm\n",
      "\n",
      "Location: Western Ghats, India (10.7449, 76.7827)\n",
      "Development Scenario: Residential Area\n",
      "Risk Score: 0.2604\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 174\n",
      "  - Urban Density: 0.3000\n",
      "  - Water Coverage: 0.4509\n",
      "  - Temperature: 25.2°C\n",
      "  - Precipitation: 35.6mm\n",
      "\n",
      "Location: Western Ghats, India (10.7449, 76.7827)\n",
      "Development Scenario: Industrial Zone\n",
      "Risk Score: 0.3472\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 174\n",
      "  - Urban Density: 0.3000\n",
      "  - Water Coverage: 0.4509\n",
      "  - Temperature: 25.2°C\n",
      "  - Precipitation: 35.6mm\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Oceania Analysis:\n",
      "\n",
      "Location: Great Barrier Reef Coast, Australia (-16.2864, 145.6845)\n",
      "Development Scenario: Natural Reserve\n",
      "Risk Score: 0.0971\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 194\n",
      "  - Urban Density: 0.5000\n",
      "  - Water Coverage: 0.1000\n",
      "  - Temperature: 28.4°C\n",
      "  - Precipitation: 21.8mm\n",
      "\n",
      "Location: Great Barrier Reef Coast, Australia (-16.2864, 145.6845)\n",
      "Development Scenario: Agricultural Zone\n",
      "Risk Score: 0.1943\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 194\n",
      "  - Urban Density: 0.5000\n",
      "  - Water Coverage: 0.1000\n",
      "  - Temperature: 28.4°C\n",
      "  - Precipitation: 21.8mm\n",
      "\n",
      "Location: Great Barrier Reef Coast, Australia (-16.2864, 145.6845)\n",
      "Development Scenario: Residential Area\n",
      "Risk Score: 0.2914\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 194\n",
      "  - Urban Density: 0.5000\n",
      "  - Water Coverage: 0.1000\n",
      "  - Temperature: 28.4°C\n",
      "  - Precipitation: 21.8mm\n",
      "\n",
      "Location: Great Barrier Reef Coast, Australia (-16.2864, 145.6845)\n",
      "Development Scenario: Industrial Zone\n",
      "Risk Score: 0.3885\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 194\n",
      "  - Urban Density: 0.5000\n",
      "  - Water Coverage: 0.1000\n",
      "  - Temperature: 28.4°C\n",
      "  - Precipitation: 21.8mm\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Antarctica Analysis:\n",
      "\n",
      "Location: Antarctic Peninsula (-64.2314, -56.7242)\n",
      "Development Scenario: Natural Reserve\n",
      "Risk Score: 0.0569\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 33\n",
      "  - Urban Density: 0.5000\n",
      "  - Water Coverage: 0.1000\n",
      "  - Temperature: 0.2°C\n",
      "  - Precipitation: 31.9mm\n",
      "\n",
      "Location: Antarctic Peninsula (-64.2314, -56.7242)\n",
      "Development Scenario: Agricultural Zone\n",
      "Risk Score: 0.1138\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 33\n",
      "  - Urban Density: 0.5000\n",
      "  - Water Coverage: 0.1000\n",
      "  - Temperature: 0.2°C\n",
      "  - Precipitation: 31.9mm\n",
      "\n",
      "Location: Antarctic Peninsula (-64.2314, -56.7242)\n",
      "Development Scenario: Residential Area\n",
      "Risk Score: 0.1706\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 33\n",
      "  - Urban Density: 0.5000\n",
      "  - Water Coverage: 0.1000\n",
      "  - Temperature: 0.2°C\n",
      "  - Precipitation: 31.9mm\n",
      "\n",
      "Location: Antarctic Peninsula (-64.2314, -56.7242)\n",
      "Development Scenario: Industrial Zone\n",
      "Risk Score: 0.2275\n",
      "Environmental Factors:\n",
      "  - Green Cover Index: 0.0000\n",
      "  - Species Count: 33\n",
      "  - Urban Density: 0.5000\n",
      "  - Water Coverage: 0.1000\n",
      "  - Temperature: 0.2°C\n",
      "  - Precipitation: 31.9mm\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Summary Statistics:\n",
      "Average Risk Score by Development Scenario:\n",
      "development_scenario\n",
      "Agricultural Zone    0.1530\n",
      "Industrial Zone      0.3061\n",
      "Natural Reserve      0.0765\n",
      "Residential Area     0.2296\n",
      "Name: risk_score, dtype: float64\n",
      "\n",
      "Highest Risk Locations:\n",
      "        continent                             location development_scenario  \\\n",
      "23        Oceania  Great Barrier Reef Coast, Australia      Industrial Zone   \n",
      "19           Asia                 Western Ghats, India      Industrial Zone   \n",
      "15         Africa                  Serengeti, Tanzania      Industrial Zone   \n",
      "7   South America            Amazon Rainforest, Brazil      Industrial Zone   \n",
      "22        Oceania  Great Barrier Reef Coast, Australia     Residential Area   \n",
      "\n",
      "    risk_score  \n",
      "23    0.388500  \n",
      "19    0.347248  \n",
      "15    0.327312  \n",
      "7     0.314022  \n",
      "22    0.291375  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from typing import Dict, List\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define development scenarios\n",
    "DEVELOPMENT_SCENARIOS = {\n",
    "    \"Natural Reserve\": \"green-based use\",\n",
    "    \"Agricultural Zone\": \"agricultural use\",\n",
    "    \"Residential Area\": \"urban home-type use\",\n",
    "    \"Industrial Zone\": \"commercial/industrial use\"\n",
    "}\n",
    "\n",
    "# Representative locations for each continent\n",
    "CONTINENTAL_LOCATIONS = [\n",
    "    {\n",
    "        \"continent\": \"North America\",\n",
    "        \"location\": \"Yellowstone, USA\",\n",
    "        \"lat\": 44.4280,\n",
    "        \"lon\": -110.5885\n",
    "    },\n",
    "    {\n",
    "        \"continent\": \"South America\",\n",
    "        \"location\": \"Amazon Rainforest, Brazil\",\n",
    "        \"lat\": -3.4653,\n",
    "        \"lon\": -62.2159\n",
    "    },\n",
    "    {\n",
    "        \"continent\": \"Europe\",\n",
    "        \"location\": \"Black Forest, Germany\",\n",
    "        \"lat\": 47.8044,\n",
    "        \"lon\": 8.1735\n",
    "    },\n",
    "    {\n",
    "        \"continent\": \"Africa\",\n",
    "        \"location\": \"Serengeti, Tanzania\",\n",
    "        \"lat\": -2.1540,\n",
    "        \"lon\": 34.6857\n",
    "    },\n",
    "    {\n",
    "        \"continent\": \"Asia\",\n",
    "        \"location\": \"Western Ghats, India\",\n",
    "        \"lat\": 10.7449,\n",
    "        \"lon\": 76.7827\n",
    "    },\n",
    "    {\n",
    "        \"continent\": \"Oceania\",\n",
    "        \"location\": \"Great Barrier Reef Coast, Australia\",\n",
    "        \"lat\": -16.2864,\n",
    "        \"lon\": 145.6845\n",
    "    },\n",
    "    {\n",
    "        \"continent\": \"Antarctica\",\n",
    "        \"location\": \"Antarctic Peninsula\",\n",
    "        \"lat\": -64.2314,\n",
    "        \"lon\": -56.7242\n",
    "    }\n",
    "]\n",
    "\n",
    "def calculate_location_risk(lat: float, lon: float, location_name: str, continent: str) -> List[Dict]:\n",
    "    \"\"\"Calculate biodiversity risk scores for all development scenarios at a location.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    try:\n",
    "        # Fetch environmental data\n",
    "        climate_data = fetch_climate_data(lat, lon)\n",
    "        green_cover = fetch_green_cover_data(lat, lon)\n",
    "        species_count = fetch_biodiversity_data(lat, lon)\n",
    "        urban_usage = fetch_land_usage_data(lat, lon)\n",
    "        water_coverage = fetch_water_coverage_data(lat, lon)\n",
    "        \n",
    "        # Calculate risk scores for each development scenario\n",
    "        for scenario_name, land_use_type in DEVELOPMENT_SCENARIOS.items():\n",
    "            risk_score = generate_risk_score(\n",
    "                ndvi=green_cover,\n",
    "                species_richness=species_count,\n",
    "                urban_land_usage=urban_usage,\n",
    "                water_coverage=water_coverage,\n",
    "                land_use_type=land_use_type\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                \"continent\": continent,\n",
    "                \"location\": location_name,\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lon,\n",
    "                \"development_scenario\": scenario_name,\n",
    "                \"risk_score\": risk_score,\n",
    "                \"environmental_factors\": {\n",
    "                    \"green_cover\": green_cover,\n",
    "                    \"species_count\": species_count,\n",
    "                    \"urban_density\": urban_usage,\n",
    "                    \"water_coverage\": water_coverage,\n",
    "                    \"temperature\": climate_data.get(\"temperature\") if climate_data else None,\n",
    "                    \"precipitation\": climate_data.get(\"precipitation\") if climate_data else None\n",
    "                }\n",
    "            })\n",
    "            \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating risk for {location_name}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    \"\"\"Calculate and display biodiversity risk scores for all locations.\"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for location in CONTINENTAL_LOCATIONS:\n",
    "        logger.info(f\"Analyzing {location['location']} ({location['continent']})\")\n",
    "        results = calculate_location_risk(\n",
    "            location[\"lat\"],\n",
    "            location[\"lon\"],\n",
    "            location[\"location\"],\n",
    "            location[\"continent\"]\n",
    "        )\n",
    "        all_results.extend(results)\n",
    "    \n",
    "    # Create DataFrame for analysis\n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nBiodiversity Risk Analysis by Continental Location and Development Scenario\")\n",
    "    print(f\"Analysis Date (UTC): {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"\\nRisk Score Scale: 0 (Lowest Risk) to 1 (Highest Risk)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for continent in df[\"continent\"].unique():\n",
    "        print(f\"\\n{continent} Analysis:\")\n",
    "        continent_data = df[df[\"continent\"] == continent]\n",
    "        \n",
    "        for _, row in continent_data.iterrows():\n",
    "            env_factors = row[\"environmental_factors\"]\n",
    "            print(f\"\\nLocation: {row['location']} ({row['latitude']:.4f}, {row['longitude']:.4f})\")\n",
    "            print(f\"Development Scenario: {row['development_scenario']}\")\n",
    "            print(f\"Risk Score: {row['risk_score']:.4f}\")\n",
    "            print(f\"Environmental Factors:\")\n",
    "            print(f\"  - Green Cover Index: {env_factors['green_cover']:.4f}\")\n",
    "            print(f\"  - Species Count: {env_factors['species_count']}\")\n",
    "            print(f\"  - Urban Density: {env_factors['urban_density']:.4f}\")\n",
    "            print(f\"  - Water Coverage: {env_factors['water_coverage']:.4f}\")\n",
    "            if env_factors['temperature'] is not None:\n",
    "                print(f\"  - Temperature: {env_factors['temperature']:.1f}°C\")\n",
    "            if env_factors['precipitation'] is not None:\n",
    "                print(f\"  - Precipitation: {env_factors['precipitation']:.1f}mm\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(f\"Average Risk Score by Development Scenario:\")\n",
    "    print(df.groupby(\"development_scenario\")[\"risk_score\"].mean().round(4))\n",
    "    print(\"\\nHighest Risk Locations:\")\n",
    "    print(df.nlargest(5, \"risk_score\")[[\"continent\", \"location\", \"development_scenario\", \"risk_score\"]])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8439edfc-417e-4a5e-90b7-239e0620aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [\n",
    "    {\n",
    "        \"Latitude\": -3.4653,\n",
    "        \"Longitude\": 114.6984,\n",
    "        \"Land Use Type\": \"green-based\",\n",
    "        \"Biodiversity Level\": \"high\",\n",
    "        \"Risk Score\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 34.0522,\n",
    "        \"Longitude\": -118.2437,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.8\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 51.5074,\n",
    "        \"Longitude\": -0.1278,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 35.6895,\n",
    "        \"Longitude\": 139.6917,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": -33.8688,\n",
    "        \"Longitude\": 151.2093,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.4\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 55.7558,\n",
    "        \"Longitude\": 37.6173,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.6\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 40.7128,\n",
    "        \"Longitude\": -74.0060,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": -23.5505,\n",
    "        \"Longitude\": -46.6333,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 19.4326,\n",
    "        \"Longitude\": -99.1332,\n",
    "        \"Land Use Type\": \"agricultural\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.3\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 48.8566,\n",
    "        \"Longitude\": 2.3522,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 28.6139,\n",
    "        \"Longitude\": 77.2090,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": -1.2921,\n",
    "        \"Longitude\": 36.8219,\n",
    "        \"Land Use Type\": \"green-based\",\n",
    "        \"Biodiversity Level\": \"high\",\n",
    "        \"Risk Score\": 0.1\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 60.1699,\n",
    "        \"Longitude\": 24.9384,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.4\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 35.6762,\n",
    "        \"Longitude\": 139.6503,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.6\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": -34.6037,\n",
    "        \"Longitude\": -58.3816,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 37.7749,\n",
    "        \"Longitude\": -122.4194,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": -22.9068,\n",
    "        \"Longitude\": -43.1729,\n",
    "        \"Land Use Type\": \"green-based\",\n",
    "        \"Biodiversity Level\": \"high\",\n",
    "        \"Risk Score\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 52.5200,\n",
    "        \"Longitude\": 13.4050,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 1.3521,\n",
    "        \"Longitude\": 103.8198,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.6\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": -26.2041,\n",
    "        \"Longitude\": 28.0473,\n",
    "        \"Land Use Type\": \"agricultural\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.3\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 35.6895,\n",
    "        \"Longitude\": 51.3890,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 34.0522,\n",
    "        \"Longitude\": -118.2437,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 55.9533,\n",
    "        \"Longitude\": -3.1883,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.6\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 59.3293,\n",
    "        \"Longitude\": 18.0686,\n",
    "        \"Land Use Type\": \"agricultural\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.3\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 31.2304,\n",
    "        \"Longitude\": 121.4737,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": -19.9167,\n",
    "        \"Longitude\": -43.9345,\n",
    "        \"Land Use Type\": \"green-based\",\n",
    "        \"Biodiversity Level\": \"high\",\n",
    "        \"Risk Score\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 45.4642,\n",
    "        \"Longitude\": 9.19,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 41.9028,\n",
    "        \"Longitude\": 12.4964,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.6\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": -34.6037,\n",
    "        \"Longitude\": -58.3816,\n",
    "        \"Land Use Type\": \"agricultural\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.3\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 34.0522,\n",
    "        \"Longitude\": -118.2437,\n",
    "        \"Land Use Type\": \"green-based\",\n",
    "        \"Biodiversity Level\": \"high\",\n",
    "        \"Risk Score\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 35.6762,\n",
    "        \"Longitude\": 139.6503,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 28.7041,\n",
    "        \"Longitude\": 77.1025,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": -33.8688,\n",
    "        \"Longitude\": 151.2093,\n",
    "        \"Land Use Type\": \"agricultural\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.3\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 52.5200,\n",
    "        \"Longitude\": 13.4050,\n",
    "        \"Land Use Type\": \"green-based\",\n",
    "        \"Biodiversity Level\": \"high\",\n",
    "        \"Risk Score\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 39.9042,\n",
    "        \"Longitude\": 116.4074,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 55.7558,\n",
    "        \"Longitude\": 37.6173,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.6\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 35.6895,\n",
    "        \"Longitude\": 51.3890,\n",
    "        \"Land Use Type\": \"agricultural\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.3\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": -25.2744,\n",
    "        \"Longitude\": 133.7751,\n",
    "        \"Land Use Type\": \"green-based\",\n",
    "        \"Biodiversity Level\": \"high\",\n",
    "        \"Risk Score\": 0.1\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 19.0760,\n",
    "        \"Longitude\": 72.8777,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": -34.6037,\n",
    "        \"Longitude\": -58.3816,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 1.3521,\n",
    "        \"Longitude\": 103.8198,\n",
    "        \"Land Use Type\": \"agricultural\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.3\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 34.0522,\n",
    "        \"Longitude\": -118.2437,\n",
    "        \"Land Use Type\": \"green-based\",\n",
    "        \"Biodiversity Level\": \"high\",\n",
    "        \"Risk Score\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 51.5074,\n",
    "        \"Longitude\": -0.1278,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 35.6762,\n",
    "        \"Longitude\": 139.6503,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": -33.8688,\n",
    "        \"Longitude\": 151.2093,\n",
    "        \"Land Use Type\": \"agricultural\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.3\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 40.7128,\n",
    "        \"Longitude\": -74.0060,\n",
    "        \"Land Use Type\": \"green-based\",\n",
    "        \"Biodiversity Level\": \"high\",\n",
    "        \"Risk Score\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 55.9533,\n",
    "        \"Longitude\": -3.1883,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 28.6139,\n",
    "        \"Longitude\": 77.2090,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": -1.2921,\n",
    "        \"Longitude\": 36.8219,\n",
    "        \"Land Use Type\": \"agricultural\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.3\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 34.0522,\n",
    "        \"Longitude\": -118.2437,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 35.6895,\n",
    "        \"Longitude\": 51.3890,\n",
    "        \"Land Use Type\": \"green-based\",\n",
    "        \"Biodiversity Level\": \"high\",\n",
    "        \"Risk Score\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 19.4326,\n",
    "        \"Longitude\": -99.1332,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 52.5200,\n",
    "        \"Longitude\": 13.4050,\n",
    "        \"Land Use Type\": \"commercial/industrial\",\n",
    "        \"Biodiversity Level\": \"low\",\n",
    "        \"Risk Score\": 0.6\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": -33.8688,\n",
    "        \"Longitude\": 151.2093,\n",
    "        \"Land Use Type\": \"green-based\",\n",
    "        \"Biodiversity Level\": \"high\",\n",
    "        \"Risk Score\": 0.1\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 41.9028,\n",
    "        \"Longitude\": 12.4964,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 34.0522,\n",
    "        \"Longitude\": -118.2437,\n",
    "        \"Land Use Type\": \"agricultural\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.3\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 35.6762,\n",
    "        \"Longitude\": 139.6503,\n",
    "        \"Land Use Type\": \"green-based\",\n",
    "        \"Biodiversity Level\": \"high\",\n",
    "        \"Risk Score\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"Latitude\": 55.7558,\n",
    "        \"Longitude\": 37.6173,\n",
    "        \"Land Use Type\": \"urban home-type\",\n",
    "        \"Biodiversity Level\": \"medium\",\n",
    "        \"Risk Score\": 0.5\n",
    "    }\n",
    "]\n",
    "data = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24dca5de-3ed1-490e-b1e2-e8a5aa36045e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Land Use Type</th>\n",
       "      <th>Biodiversity Level</th>\n",
       "      <th>Risk Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.4653</td>\n",
       "      <td>114.6984</td>\n",
       "      <td>green-based</td>\n",
       "      <td>high</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0522</td>\n",
       "      <td>-118.2437</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.5074</td>\n",
       "      <td>-0.1278</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.6895</td>\n",
       "      <td>139.6917</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-33.8688</td>\n",
       "      <td>151.2093</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.7558</td>\n",
       "      <td>37.6173</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.7128</td>\n",
       "      <td>-74.0060</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-23.5505</td>\n",
       "      <td>-46.6333</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.4326</td>\n",
       "      <td>-99.1332</td>\n",
       "      <td>agricultural</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48.8566</td>\n",
       "      <td>2.3522</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28.6139</td>\n",
       "      <td>77.2090</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.2921</td>\n",
       "      <td>36.8219</td>\n",
       "      <td>green-based</td>\n",
       "      <td>high</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60.1699</td>\n",
       "      <td>24.9384</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>35.6762</td>\n",
       "      <td>139.6503</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-34.6037</td>\n",
       "      <td>-58.3816</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>37.7749</td>\n",
       "      <td>-122.4194</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-22.9068</td>\n",
       "      <td>-43.1729</td>\n",
       "      <td>green-based</td>\n",
       "      <td>high</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>52.5200</td>\n",
       "      <td>13.4050</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.3521</td>\n",
       "      <td>103.8198</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-26.2041</td>\n",
       "      <td>28.0473</td>\n",
       "      <td>agricultural</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35.6895</td>\n",
       "      <td>51.3890</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34.0522</td>\n",
       "      <td>-118.2437</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>low</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>55.9533</td>\n",
       "      <td>-3.1883</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>59.3293</td>\n",
       "      <td>18.0686</td>\n",
       "      <td>agricultural</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>31.2304</td>\n",
       "      <td>121.4737</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-19.9167</td>\n",
       "      <td>-43.9345</td>\n",
       "      <td>green-based</td>\n",
       "      <td>high</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>45.4642</td>\n",
       "      <td>9.1900</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>41.9028</td>\n",
       "      <td>12.4964</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-34.6037</td>\n",
       "      <td>-58.3816</td>\n",
       "      <td>agricultural</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>34.0522</td>\n",
       "      <td>-118.2437</td>\n",
       "      <td>green-based</td>\n",
       "      <td>high</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>35.6762</td>\n",
       "      <td>139.6503</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>28.7041</td>\n",
       "      <td>77.1025</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-33.8688</td>\n",
       "      <td>151.2093</td>\n",
       "      <td>agricultural</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>52.5200</td>\n",
       "      <td>13.4050</td>\n",
       "      <td>green-based</td>\n",
       "      <td>high</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>39.9042</td>\n",
       "      <td>116.4074</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>55.7558</td>\n",
       "      <td>37.6173</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>35.6895</td>\n",
       "      <td>51.3890</td>\n",
       "      <td>agricultural</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-25.2744</td>\n",
       "      <td>133.7751</td>\n",
       "      <td>green-based</td>\n",
       "      <td>high</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19.0760</td>\n",
       "      <td>72.8777</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-34.6037</td>\n",
       "      <td>-58.3816</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.3521</td>\n",
       "      <td>103.8198</td>\n",
       "      <td>agricultural</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>34.0522</td>\n",
       "      <td>-118.2437</td>\n",
       "      <td>green-based</td>\n",
       "      <td>high</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>51.5074</td>\n",
       "      <td>-0.1278</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>35.6762</td>\n",
       "      <td>139.6503</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-33.8688</td>\n",
       "      <td>151.2093</td>\n",
       "      <td>agricultural</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>40.7128</td>\n",
       "      <td>-74.0060</td>\n",
       "      <td>green-based</td>\n",
       "      <td>high</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>55.9533</td>\n",
       "      <td>-3.1883</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>28.6139</td>\n",
       "      <td>77.2090</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-1.2921</td>\n",
       "      <td>36.8219</td>\n",
       "      <td>agricultural</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>34.0522</td>\n",
       "      <td>-118.2437</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>35.6895</td>\n",
       "      <td>51.3890</td>\n",
       "      <td>green-based</td>\n",
       "      <td>high</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>19.4326</td>\n",
       "      <td>-99.1332</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52.5200</td>\n",
       "      <td>13.4050</td>\n",
       "      <td>commercial/industrial</td>\n",
       "      <td>low</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-33.8688</td>\n",
       "      <td>151.2093</td>\n",
       "      <td>green-based</td>\n",
       "      <td>high</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>41.9028</td>\n",
       "      <td>12.4964</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>34.0522</td>\n",
       "      <td>-118.2437</td>\n",
       "      <td>agricultural</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>35.6762</td>\n",
       "      <td>139.6503</td>\n",
       "      <td>green-based</td>\n",
       "      <td>high</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>55.7558</td>\n",
       "      <td>37.6173</td>\n",
       "      <td>urban home-type</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude          Land Use Type Biodiversity Level  Risk Score\n",
       "0    -3.4653   114.6984            green-based               high         0.2\n",
       "1    34.0522  -118.2437  commercial/industrial                low         0.8\n",
       "2    51.5074    -0.1278        urban home-type             medium         0.5\n",
       "3    35.6895   139.6917  commercial/industrial                low         0.7\n",
       "4   -33.8688   151.2093        urban home-type             medium         0.4\n",
       "5    55.7558    37.6173  commercial/industrial                low         0.6\n",
       "6    40.7128   -74.0060        urban home-type             medium         0.5\n",
       "7   -23.5505   -46.6333  commercial/industrial                low         0.7\n",
       "8    19.4326   -99.1332           agricultural             medium         0.3\n",
       "9    48.8566     2.3522        urban home-type             medium         0.5\n",
       "10   28.6139    77.2090  commercial/industrial                low         0.7\n",
       "11   -1.2921    36.8219            green-based               high         0.1\n",
       "12   60.1699    24.9384        urban home-type             medium         0.4\n",
       "13   35.6762   139.6503  commercial/industrial                low         0.6\n",
       "14  -34.6037   -58.3816        urban home-type             medium         0.5\n",
       "15   37.7749  -122.4194  commercial/industrial                low         0.7\n",
       "16  -22.9068   -43.1729            green-based               high         0.2\n",
       "17   52.5200    13.4050        urban home-type             medium         0.5\n",
       "18    1.3521   103.8198  commercial/industrial                low         0.6\n",
       "19  -26.2041    28.0473           agricultural             medium         0.3\n",
       "20   35.6895    51.3890        urban home-type             medium         0.5\n",
       "21   34.0522  -118.2437        urban home-type                low         0.7\n",
       "22   55.9533    -3.1883  commercial/industrial                low         0.6\n",
       "23   59.3293    18.0686           agricultural             medium         0.3\n",
       "24   31.2304   121.4737  commercial/industrial                low         0.7\n",
       "25  -19.9167   -43.9345            green-based               high         0.2\n",
       "26   45.4642     9.1900        urban home-type             medium         0.5\n",
       "27   41.9028    12.4964  commercial/industrial                low         0.6\n",
       "28  -34.6037   -58.3816           agricultural             medium         0.3\n",
       "29   34.0522  -118.2437            green-based               high         0.2\n",
       "30   35.6762   139.6503        urban home-type             medium         0.5\n",
       "31   28.7041    77.1025  commercial/industrial                low         0.7\n",
       "32  -33.8688   151.2093           agricultural             medium         0.3\n",
       "33   52.5200    13.4050            green-based               high         0.2\n",
       "34   39.9042   116.4074        urban home-type             medium         0.5\n",
       "35   55.7558    37.6173  commercial/industrial                low         0.6\n",
       "36   35.6895    51.3890           agricultural             medium         0.3\n",
       "37  -25.2744   133.7751            green-based               high         0.1\n",
       "38   19.0760    72.8777        urban home-type             medium         0.5\n",
       "39  -34.6037   -58.3816  commercial/industrial                low         0.7\n",
       "40    1.3521   103.8198           agricultural             medium         0.3\n",
       "41   34.0522  -118.2437            green-based               high         0.2\n",
       "42   51.5074    -0.1278        urban home-type             medium         0.5\n",
       "43   35.6762   139.6503  commercial/industrial                low         0.7\n",
       "44  -33.8688   151.2093           agricultural             medium         0.3\n",
       "45   40.7128   -74.0060            green-based               high         0.2\n",
       "46   55.9533    -3.1883        urban home-type             medium         0.5\n",
       "47   28.6139    77.2090  commercial/industrial                low         0.7\n",
       "48   -1.2921    36.8219           agricultural             medium         0.3\n",
       "49   34.0522  -118.2437  commercial/industrial                low         0.7\n",
       "50   35.6895    51.3890            green-based               high         0.2\n",
       "51   19.4326   -99.1332        urban home-type             medium         0.5\n",
       "52   52.5200    13.4050  commercial/industrial                low         0.6\n",
       "53  -33.8688   151.2093            green-based               high         0.1\n",
       "54   41.9028    12.4964        urban home-type             medium         0.5\n",
       "55   34.0522  -118.2437           agricultural             medium         0.3\n",
       "56   35.6762   139.6503            green-based               high         0.2\n",
       "57   55.7558    37.6173        urban home-type             medium         0.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68a98c34-9618-4c41-a119-bdef1fef39a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ee'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 246\u001b[0m\n\u001b[0;32m    243\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in fallback water coverage calculation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.1\u001b[39m  \u001b[38;5;66;03m# Default low water coverage\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mee\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ee'"
     ]
    }
   ],
   "source": [
    "def fetch_climate_data(lat: float, lon: float) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Fetch climate data using OpenWeatherMap API with 5-day precipitation forecast.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get current weather\n",
    "        current_url = f\"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
    "        current_response = requests.get(current_url)\n",
    "        current_response.raise_for_status()\n",
    "        current_data = current_response.json()\n",
    "        \n",
    "        # Get 5 day forecast with 3-hour steps\n",
    "        forecast_url = f\"https://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
    "        forecast_response = requests.get(forecast_url)\n",
    "        forecast_response.raise_for_status()\n",
    "        forecast_data = forecast_response.json()\n",
    "        \n",
    "        # Calculate average precipitation from forecast\n",
    "        total_precipitation = 0\n",
    "        count = 0\n",
    "        \n",
    "        for item in forecast_data.get('list', []):\n",
    "            # Get precipitation (rain or snow)\n",
    "            rain_amount = item.get('rain', {}).get('3h', 0)\n",
    "            snow_amount = item.get('snow', {}).get('3h', 0)\n",
    "            total_precipitation += rain_amount + snow_amount\n",
    "            count += 1\n",
    "        \n",
    "        # Convert 3-hourly precipitation to daily average\n",
    "        avg_daily_precipitation = (total_precipitation / count) * 8 if count > 0 else 0\n",
    "        # Estimate monthly precipitation (multiply by 30 days)\n",
    "        estimated_monthly_precipitation = avg_daily_precipitation * 30\n",
    "        \n",
    "        return {\n",
    "            \"temperature\": current_data[\"main\"][\"temp\"],\n",
    "            \"precipitation\": estimated_monthly_precipitation,\n",
    "            \"humidity\": current_data[\"main\"][\"humidity\"],\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching climate data for {lat}, {lon}: {str(e)}\")\n",
    "        return None\n",
    "    finally:\n",
    "        time.sleep(REQUEST_DELAY)\n",
    "import requests\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import Dict, Tuple\n",
    "from shapely.geometry import Polygon, MultiPolygon, LineString\n",
    "from shapely.ops import unary_union\n",
    "import json\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def _get_overpass_data(query: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Helper function to fetch data from Overpass API.\n",
    "    \"\"\"\n",
    "    overpass_url = \"https://overpass-api.de/api/interpreter\"\n",
    "    try:\n",
    "        response = requests.post(overpass_url, data={'data': query})\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Overpass API error: {str(e)}\")\n",
    "        return {'elements': []}\n",
    "\n",
    "def fetch_land_usage_data(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fetch land usage data using Overpass API.\n",
    "    Returns urban density index between 0 and 1.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calculate bounding box (1km radius)\n",
    "        radius = 1000  # meters\n",
    "        deg_radius = radius / 111320  # Convert meters to degrees (approximate)\n",
    "        \n",
    "        # Overpass query for buildings and roads\n",
    "        query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          way[\"building\"](around:{radius},{lat},{lon});\n",
    "          way[\"highway\"](around:{radius},{lat},{lon});\n",
    "        );\n",
    "        out body geom;\n",
    "        \"\"\"\n",
    "        \n",
    "        data = _get_overpass_data(query)\n",
    "        \n",
    "        if not data['elements']:\n",
    "            # Fallback to secondary API\n",
    "            return _fetch_land_usage_fallback(lat, lon)\n",
    "        \n",
    "        # Calculate areas and lengths\n",
    "        total_area = np.pi * (radius ** 2)  # Total circular area in square meters\n",
    "        building_area = 0\n",
    "        road_length = 0\n",
    "        \n",
    "        for element in data['elements']:\n",
    "            if 'geometry' in element:\n",
    "                coords = [(p['lon'], p['lat']) for p in element['geometry']]\n",
    "                if element.get('tags', {}).get('building'):\n",
    "                    # Calculate building area\n",
    "                    if len(coords) >= 3:\n",
    "                        try:\n",
    "                            polygon = Polygon(coords)\n",
    "                            building_area += polygon.area * 111320 * 111320  # Convert to square meters\n",
    "                        except:\n",
    "                            continue\n",
    "                elif element.get('tags', {}).get('highway'):\n",
    "                    # Calculate road length\n",
    "                    if len(coords) >= 2:\n",
    "                        try:\n",
    "                            line = LineString(coords)\n",
    "                            road_length += line.length * 111320  # Convert to meters\n",
    "                        except:\n",
    "                            continue\n",
    "        \n",
    "        # Calculate urban density\n",
    "        building_density = min(building_area / total_area, 0.7)  # Cap at 70%\n",
    "        road_density = min(road_length / (radius * 2 * np.pi), 0.3)  # Cap at 30%\n",
    "        \n",
    "        urban_density = building_density + road_density\n",
    "        return min(max(urban_density, 0), 1)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in primary land usage calculation: {str(e)}\")\n",
    "        return _fetch_land_usage_fallback(lat, lon)\n",
    "\n",
    "def _fetch_land_usage_fallback(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fallback method using OpenStreetMap Nominatim API for land use data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use Nominatim API to get area details\n",
    "        nominatim_url = f\"https://nominatim.openstreetmap.org/reverse?lat={lat}&lon={lon}&format=json&zoom=14\"\n",
    "        headers = {'User-Agent': 'Urban Density Calculator 1.0'}\n",
    "        \n",
    "        response = requests.get(nominatim_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Analyze address components and category\n",
    "        address = data.get('address', {})\n",
    "        category = data.get('category', '')\n",
    "        \n",
    "        # Calculate urban density based on location type\n",
    "        if any(k in address for k in ['city', 'town', 'suburb']):\n",
    "            return 0.8  # Urban area\n",
    "        elif 'village' in address:\n",
    "            return 0.4  # Rural settlement\n",
    "        elif any(k in address for k in ['industrial', 'commercial']):\n",
    "            return 0.9  # Industrial/commercial area\n",
    "        elif any(k in address for k in ['forest', 'park', 'nature_reserve']):\n",
    "            return 0.1  # Natural area\n",
    "        else:\n",
    "            return 0.5  # Default semi-urban\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in fallback land usage calculation: {str(e)}\")\n",
    "        return 0.5  # Default value\n",
    "\n",
    "def fetch_water_coverage_data(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fetch water coverage data using Overpass API.\n",
    "    Returns water coverage ratio between 0 and 1.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calculate bounding box (1km radius)\n",
    "        radius = 1000  # meters\n",
    "        \n",
    "        # Overpass query for water features\n",
    "        query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          way[\"natural\"=\"water\"](around:{radius},{lat},{lon});\n",
    "          way[\"waterway\"](around:{radius},{lat},{lon});\n",
    "          way[\"water\"](around:{radius},{lat},{lon});\n",
    "          way[\"natural\"=\"wetland\"](around:{radius},{lat},{lon});\n",
    "        );\n",
    "        out body geom;\n",
    "        \"\"\"\n",
    "        \n",
    "        data = _get_overpass_data(query)\n",
    "        \n",
    "        if not data['elements']:\n",
    "            # Fallback to secondary API\n",
    "            return _fetch_water_coverage_fallback(lat, lon)\n",
    "        \n",
    "        # Calculate areas\n",
    "        total_area = np.pi * (radius ** 2)  # Total circular area in square meters\n",
    "        water_area = 0\n",
    "        \n",
    "        for element in data['elements']:\n",
    "            if 'geometry' in element:\n",
    "                coords = [(p['lon'], p['lat']) for p in element['geometry']]\n",
    "                if len(coords) >= 3:\n",
    "                    try:\n",
    "                        polygon = Polygon(coords)\n",
    "                        water_area += polygon.area * 111320 * 111320  # Convert to square meters\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        water_coverage = water_area / total_area\n",
    "        return min(max(water_coverage, 0), 1)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in primary water coverage calculation: {str(e)}\")\n",
    "        return _fetch_water_coverage_fallback(lat, lon)\n",
    "\n",
    "def _fetch_water_coverage_fallback(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fallback method using OpenMeteo API for water proximity data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use OpenMeteo API for water-related data\n",
    "        url = f\"https://marine-api.open-meteo.com/v1/marine?latitude={lat}&longitude={lon}&daily=wave_height\"\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'daily' in data and 'wave_height' in data['daily']:\n",
    "            # If wave height data is available, location is near water\n",
    "            return min(max(np.mean(data['daily']['wave_height']) / 2, 0), 1)\n",
    "            \n",
    "        # If no marine data, check for inland water bodies using Nominatim\n",
    "        nominatim_url = f\"https://nominatim.openstreetmap.org/reverse?lat={lat}&lon={lon}&format=json&zoom=14\"\n",
    "        headers = {'User-Agent': 'Water Coverage Calculator 1.0'}\n",
    "        \n",
    "        response = requests.get(nominatim_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Check location type\n",
    "        if any(water_type in str(data).lower() for water_type in ['lake', 'river', 'sea', 'ocean', 'bay', 'wetland']):\n",
    "            return 0.7  # Significant water presence\n",
    "        return 0.1  # Minimal water presence\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in fallback water coverage calculation: {str(e)}\")\n",
    "        return 0.1  # Default low water coverage\n",
    "\n",
    "import ee\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def fetch_green_cover_data(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fetch green cover data using Copernicus Global Land Service API.\n",
    "    Uses NDVI (Normalized Difference Vegetation Index) data.\n",
    "    \n",
    "    Args:\n",
    "        lat (float): Latitude\n",
    "        lon (float): Longitude\n",
    "    \n",
    "    Returns:\n",
    "        float: NDVI value between 0 and 1\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Using Copernicus Global Land Service API\n",
    "        base_url = \"https://land.copernicus.vgt.vito.be/REST/TimeSeries/1.0/extract\"\n",
    "        \n",
    "        # Current date and one month ago\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=30)\n",
    "        \n",
    "        params = {\n",
    "            'lat': lat,\n",
    "            'lon': lon,\n",
    "            'startdate': start_date.strftime('%Y-%m-%d'),\n",
    "            'enddate': end_date.strftime('%Y-%m-%d'),\n",
    "            'collection': 'NDVI_V2',\n",
    "            'format': 'json'\n",
    "        }\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0',\n",
    "            'Accept': 'application/json'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(base_url, params=params, headers=headers)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            # Fallback to alternative API: OpenMeteo\n",
    "            return _fetch_green_cover_fallback(lat, lon)\n",
    "            \n",
    "        data = response.json()\n",
    "        ndvi_values = [item['NDVI'] for item in data['results'] if 'NDVI' in item]\n",
    "        \n",
    "        if ndvi_values:\n",
    "            # NDVI values are typically between -1 and 1\n",
    "            # Normalize to 0-1 range\n",
    "            avg_ndvi = np.mean(ndvi_values)\n",
    "            normalized_ndvi = (avg_ndvi + 1) / 2\n",
    "            return max(min(normalized_ndvi, 1), 0)\n",
    "            \n",
    "        return _fetch_green_cover_fallback(lat, lon)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in primary green cover fetch: {str(e)}\")\n",
    "        return _fetch_green_cover_fallback(lat, lon)\n",
    "\n",
    "def _fetch_green_cover_fallback(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fallback method using OpenMeteo API for vegetation data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # OpenMeteo API for soil and vegetation data\n",
    "        url = (f\"https://api.open-meteo.com/v1/forecast?\"\n",
    "               f\"latitude={lat}&longitude={lon}\"\n",
    "               f\"&hourly=soil_moisture_0_1cm,soil_moisture_1_3cm\"\n",
    "               f\"&daily=et0_fao_evapotranspiration\")\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Calculate green cover proxy using soil moisture and evapotranspiration\n",
    "        soil_moisture = np.mean(data['hourly']['soil_moisture_0_1cm'][:24])  # First 24 hours\n",
    "        evapotranspiration = data['daily']['et0_fao_evapotranspiration'][0]  # First day\n",
    "        \n",
    "        # Combine metrics to estimate vegetation cover\n",
    "        # Normalize values based on typical ranges\n",
    "        soil_moisture_norm = min(soil_moisture / 50, 1)  # Typical range 0-50\n",
    "        evapotrans_norm = min(evapotranspiration / 10, 1)  # Typical range 0-10\n",
    "        \n",
    "        # Weight the factors\n",
    "        green_cover = (soil_moisture_norm * 0.6 + evapotrans_norm * 0.4)\n",
    "        \n",
    "        return max(min(green_cover, 1), 0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in fallback green cover fetch: {str(e)}\")\n",
    "        return _fetch_green_cover_last_resort(lat, lon)\n",
    "\n",
    "def _fetch_green_cover_last_resort(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Last resort method using NASA POWER API for vegetation-related data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # NASA POWER API\n",
    "        base_url = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "        \n",
    "        params = {\n",
    "            'parameters': 'T2M,PRECTOT,RH2M',  # Temperature, precipitation, humidity\n",
    "            'community': 'AG',\n",
    "            'longitude': lon,\n",
    "            'latitude': lat,\n",
    "            'start': datetime.now().strftime('%Y%m%d'),\n",
    "            'end': datetime.now().strftime('%Y%m%d'),\n",
    "            'format': 'JSON'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract relevant parameters\n",
    "        temp = float(data['properties']['parameter']['T2M'][datetime.now().strftime('%Y%m%d')])\n",
    "        precip = float(data['properties']['parameter']['PRECTOT'][datetime.now().strftime('%Y%m%d')])\n",
    "        humidity = float(data['properties']['parameter']['RH2M'][datetime.now().strftime('%Y%m%d')])\n",
    "        \n",
    "        # Create a simple vegetation index based on environmental conditions\n",
    "        # This is a rough approximation based on typical conditions favorable for vegetation\n",
    "        temp_factor = max(0, min(1 - abs(temp - 20) / 30, 1))  # Optimal temp around 20°C\n",
    "        precip_factor = min(precip / 10, 1)  # Normalize precipitation (0-10mm)\n",
    "        humidity_factor = humidity / 100  # Humidity is already 0-100\n",
    "        \n",
    "        # Combine factors with weights\n",
    "        green_cover = (temp_factor * 0.3 + precip_factor * 0.4 + humidity_factor * 0.3)\n",
    "        \n",
    "        return max(min(green_cover, 1), 0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in last resort green cover fetch: {str(e)}\")\n",
    "        # Return a reasonable default based on global averages\n",
    "        return 0.3  # Global average vegetation cover is roughly 30%\n",
    "\n",
    "def fetch_biodiversity_data(lat: float, lon: float) -> int:\n",
    "    \"\"\"\n",
    "    Fetch biodiversity data using GBIF API with improved species counting.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        params = {\n",
    "            \"decimalLatitude\": f\"{lat-0.5},{lat+0.5}\",\n",
    "            \"decimalLongitude\": f\"{lon-0.5},{lon+0.5}\",\n",
    "            \"limit\": 300,  # Increased limit\n",
    "            \"hasCoordinate\": True,\n",
    "            \"hasGeospatialIssue\": False\n",
    "        }\n",
    "        response = requests.get(GBIF_API_BASE, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        time.sleep(REQUEST_DELAY)\n",
    "        \n",
    "        # Count unique species\n",
    "        species_set = set()\n",
    "        for record in data.get(\"results\", []):\n",
    "            if record.get(\"species\"):\n",
    "                species_set.add(record[\"species\"])\n",
    "        \n",
    "        return len(species_set)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching biodiversity data for {lat}, {lon}: {str(e)}\")\n",
    "        return 0   \n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "\n",
    "def create_dataset_parallel(\n",
    "    regions: List[Dict[str, float]],\n",
    "    land_use_types: List[str],\n",
    "    max_workers: int = 10\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a labeled dataset across various regions with selected land use types using parallelism.\n",
    "    \n",
    "    Args:\n",
    "        regions (list): List of dictionaries containing lat/lon coordinates.\n",
    "        land_use_types (list): List of land use type strings.\n",
    "        max_workers (int): Maximum number of threads to use for parallel execution.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataset containing environmental metrics and risk scores.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    def process_region(region):\n",
    "        \"\"\"\n",
    "        Fetch environmental metrics for a single region.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            lat, lon = region[\"lat\"], region[\"lon\"]\n",
    "            logger.info(f\"Fetching data for region: {lat}, {lon}\")\n",
    "            \n",
    "            # Fetch all metrics\n",
    "            climate_data = fetch_climate_data(lat, lon)\n",
    "            biodiversity_data = fetch_biodiversity_data(lat, lon)\n",
    "            green_cover = fetch_green_cover_data(lat, lon)\n",
    "            land_usage = fetch_land_usage_data(lat, lon)\n",
    "            water_coverage = fetch_water_coverage_data(lat, lon)\n",
    "            \n",
    "            # Randomly select a land use type\n",
    "            land_use_type = random.choice(land_use_types)\n",
    "            \n",
    "            # Combine data into a single record\n",
    "            return {\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lon,\n",
    "                \"temperature\": climate_data.get(\"temperature\"),\n",
    "                \"precipitation\": climate_data.get(\"precipitation\"),\n",
    "                \"humidity\": climate_data.get(\"humidity\"),\n",
    "                \"biodiversity_index\": biodiversity_data,\n",
    "                \"green_cover\": green_cover,\n",
    "                \"land_usage\": land_usage,\n",
    "                \"water_coverage\": water_coverage,\n",
    "                \"land_use_type\": land_use_type\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing region {region}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit tasks to the executor\n",
    "        future_to_region = {executor.submit(process_region, region): region for region in regions}\n",
    "        \n",
    "        for future in as_completed(future_to_region):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                data.append(result)\n",
    "\n",
    "    # Create DataFrame from collected data\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c0c28-9802-43ad-9ce4-fe8412d82937",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\n",
    "    {\"lat\": 10.7449, \"lon\": 92.5000},  # New York City, USA\n",
    "]\n",
    "# Define possible land use types\n",
    "land_use_types = [\n",
    "    \"green-based use\",\n",
    "]\n",
    "dataset = create_dataset(regions, land_use_types)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d65684-a99a-480d-a1fd-1a464922aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e9e8a-abd0-4d40-9fd1-a9c47a17ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = data.drop(['Biodiversity Level'],axis=1)\n",
    "df_f = pd.DataFrame(columns=cols)\n",
    "for i in range(len(dat)):\n",
    "    lat = dat.loc[i][0]\n",
    "    long = dat.loc[i][1]\n",
    "    land_use_type = dat.loc[i][2]\n",
    "    risk_score = dat.loc[i][3]\n",
    "    regions = [\n",
    "    {\"lat\": lat, \"lon\": long},]  # New York City, USA  # New Delhi, India]\n",
    "\n",
    "    land_use_types = [land_use_type]\n",
    "    dataset = create_dataset(regions, land_use_types)\n",
    "    \n",
    "    df_f = dataset\n",
    "    df_f['risk_score'] = risk_score\n",
    "    break\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b6cfd07-096f-4104-85da-950c6ba235bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]2025-01-19 01:49:22,319 - INFO - Processing region 1/1: -3.4653, 114.6984\n",
      "2025-01-19 01:49:35,923 - ERROR - Error in primary green cover fetch: Expecting value: line 1 column 1 (char 0)\n",
      "  2%|▊                                           | 1/58 [00:19<18:32, 19.52s/it]2025-01-19 01:49:41,844 - INFO - Processing region 1/1: 34.0522, -118.2437\n",
      "2025-01-19 01:49:59,899 - ERROR - Error in primary green cover fetch: Expecting value: line 1 column 1 (char 0)\n",
      "  3%|█▌                                          | 2/58 [00:49<23:56, 25.66s/it]2025-01-19 01:50:11,798 - INFO - Processing region 1/1: 51.5074, -0.1278\n",
      "2025-01-19 01:50:28,170 - ERROR - Error in primary green cover fetch: Expecting value: line 1 column 1 (char 0)\n",
      "  5%|██▎                                         | 3/58 [01:24<27:18, 29.79s/it]2025-01-19 01:50:46,501 - INFO - Processing region 1/1: 35.6895, 139.6917\n",
      "2025-01-19 01:51:03,504 - ERROR - Error in primary green cover fetch: Expecting value: line 1 column 1 (char 0)\n",
      "  7%|███                                         | 4/58 [01:56<27:35, 30.66s/it]2025-01-19 01:51:18,494 - INFO - Processing region 1/1: -33.8688, 151.2093\n",
      "  7%|███                                         | 4/58 [02:10<29:18, 32.57s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m land_use_types \u001b[38;5;241m=\u001b[39m [land_use_type]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Assuming `create_dataset` generates a DataFrame\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m dataset \u001b[38;5;241m=\u001b[39m create_dataset(regions, land_use_types)\n\u001b[1;32m     18\u001b[0m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrisk_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m risk_score\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Append the dataset to df_f\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 439\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[0;34m(regions, land_use_types)\u001b[0m\n\u001b[1;32m    436\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing region \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_regions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m climate_data \u001b[38;5;241m=\u001b[39m fetch_climate_data(lat, lon)\n\u001b[0;32m--> 439\u001b[0m biodiversity_data \u001b[38;5;241m=\u001b[39m fetch_biodiversity_data(lat, lon)\n\u001b[1;32m    440\u001b[0m green_cover \u001b[38;5;241m=\u001b[39m fetch_green_cover_data(lat, lon)\n\u001b[1;32m    441\u001b[0m land_usage \u001b[38;5;241m=\u001b[39m fetch_land_usage_data(lat, lon)\n",
      "Cell \u001b[0;32mIn[32], line 401\u001b[0m, in \u001b[0;36mfetch_biodiversity_data\u001b[0;34m(lat, lon)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    394\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    395\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecimalLatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlat\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlat\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    396\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecimalLongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlon\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlon\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhasGeospatialIssue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    400\u001b[0m     }\n\u001b[0;32m--> 401\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(GBIF_API_BASE, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m    402\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    403\u001b[0m     data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/sessions.py:746\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 746\u001b[0m     r\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(CONTENT_CHUNK_SIZE)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/response.py:1057\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m-> 1057\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/response.py:1209\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_chunk(amt)\n\u001b[1;32m   1210\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[1;32m   1211\u001b[0m     chunk, decode_content\u001b[38;5;241m=\u001b[39mdecode_content, flush_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m )\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/response.py:1155\u001b[0m, in \u001b[0;36mHTTPResponse._handle_chunk\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     returned_chunk \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# amt > self.chunk_left\u001b[39;00m\n\u001b[0;32m-> 1155\u001b[0m     returned_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left)  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# type: ignore[union-attr] # Toss the CRLF at the end of the chunk.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:640\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[1;32m    634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m    642\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create an empty DataFrame with the specified column names\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "df_f = pd.DataFrame(columns=cols)\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Iterate over rows in `dat`\n",
    "for i in tqdm(range(len(dat))):\n",
    "    lat = dat.loc[i][0]\n",
    "    long = dat.loc[i][1]\n",
    "    land_use_type = dat.loc[i][2]\n",
    "    risk_score = dat.loc[i][3]\n",
    "    regions = [{\"lat\": lat, \"lon\": long}]\n",
    "    land_use_types = [land_use_type]\n",
    "\n",
    "    # Assuming `create_dataset` generates a DataFrame\n",
    "    dataset = create_dataset(regions, land_use_types)\n",
    "    dataset['risk_score'] = risk_score\n",
    "\n",
    "    # Append the dataset to df_f\n",
    "    df_f = pd.concat([df_f, dataset], ignore_index=True)\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bea71d-9201-454c-85d4-953d030b9029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]2025-01-19 01:51:36,770 - INFO - Processing region 1/1: -3.4653, 114.6984\n",
      "2025-01-19 01:51:55,725 - ERROR - Error in primary green cover fetch: Expecting value: line 1 column 1 (char 0)\n",
      "  2%|▊                                           | 1/58 [00:24<23:14, 24.47s/it]2025-01-19 01:52:01,245 - INFO - Processing region 1/1: 34.0522, -118.2437\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create an empty list to accumulate the rows\n",
    "data = []\n",
    "\n",
    "# Iterate over rows in `dat`\n",
    "for i in tqdm(range(len(dat))):\n",
    "    lat = dat.loc[i][0]\n",
    "    long = dat.loc[i][1]\n",
    "    land_use_type = dat.loc[i][2]\n",
    "    risk_score = dat.loc[i][3]\n",
    "    regions = [{\"lat\": lat, \"lon\": long}]\n",
    "    land_use_types = [land_use_type]\n",
    "\n",
    "    # Assuming `create_dataset` generates a DataFrame\n",
    "    dataset = create_dataset(regions, land_use_types)\n",
    "    dataset['risk_score'] = risk_score\n",
    "\n",
    "    # Append rows to the list\n",
    "    data.extend(dataset.to_dict('records'))  # Convert dataset to a list of dicts and extend\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame once\n",
    "df_f = pd.DataFrame(data, columns=cols)\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd6a9de-66b2-4bd6-87d6-3e70f3ce0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a658c2c0-ef2d-41ca-9024-9b54950e3041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Assuming df_f is your DataFrame\n",
    "# Separate categorical and numerical columns\n",
    "categorical_columns = ['humidity', 'species_richness', 'land_use_type']\n",
    "numerical_columns = ['latitude', 'longitude', 'temperature', 'precipitation', \n",
    "                    'ndvi', 'urban_land_usage', 'water_coverage']\n",
    "\n",
    "# Function for data preprocessing\n",
    "def preprocess_data(df):\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Handle categorical variables\n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        label_encoders[col] = LabelEncoder()\n",
    "        df_processed[col] = label_encoders[col].fit_transform(df_processed[col])\n",
    "    \n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    df_processed[numerical_columns] = scaler.fit_transform(df_processed[numerical_columns])\n",
    "    \n",
    "    return df_processed, label_encoders, scaler\n",
    "\n",
    "# Preprocess the data\n",
    "df_processed, label_encoders, scaler = preprocess_data(df_f)\n",
    "\n",
    "# Split features and target\n",
    "X = df_processed.drop(columns=[\"risk_score\"])\n",
    "y = df_processed[\"risk_score\"]\n",
    "\n",
    "# Split data with stratification\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Model parameters\n",
    "lgb_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.8,\n",
    "    'subsample': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'random_state': 42,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "# Initialize and train models\n",
    "# Train models\n",
    "def train_model(model, X_train, y_train, X_val, y_val, model_name):\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    if model_name == \"LightGBM\":\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=(X_val, y_val),\n",
    "        )\n",
    "    elif model_name == \"CatBoost\":\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=(X_val, y_val),\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=100\n",
    "        )\n",
    "    else:  # For XGBoost\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "\n",
    "        )\n",
    "    return model\n",
    "\n",
    "# Train models\n",
    "models = {\n",
    "    \"LightGBM\": LGBMRegressor(**lgb_params),\n",
    "    \"XGBoost\": XGBRegressor(**xgb_params),\n",
    "    \"CatBoost\": CatBoostRegressor(**cat_params)\n",
    "}\n",
    "\n",
    "predictions = {}\n",
    "for name, model in models.items():\n",
    "    trained_model = train_model(model, X_train, y_train, X_val, y_val, name)\n",
    "    predictions[name] = trained_model.predict(X_val)\n",
    "\n",
    "# Weighted ensemble predictions\n",
    "weights = {\n",
    "    \"LightGBM\": 0.4,\n",
    "    \"XGBoost\": 0.3,\n",
    "    \"CatBoost\": 0.3\n",
    "}\n",
    "\n",
    "ensemble_preds = sum(predictions[model] * weight for model, weight in weights.items())\n",
    "\n",
    "# Evaluate models\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n{model_name} Metrics:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    return rmse, r2\n",
    "\n",
    "# Print evaluation metrics for each model\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(\"=\"*50)\n",
    "for name in predictions.keys():\n",
    "    evaluate_model(y_val, predictions[name], name)\n",
    "\n",
    "# Evaluate ensemble\n",
    "print(\"\\nEnsemble Model Evaluation:\")\n",
    "print(\"=\"*50)\n",
    "ensemble_rmse, ensemble_r2 = evaluate_model(y_val, ensemble_preds, \"Weighted Ensemble\")\n",
    "\n",
    "# Feature importance analysis\n",
    "def plot_feature_importance(models, feature_names):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for name, model in models.items():\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            plt.plot(feature_names, model.feature_importances_, label=name, alpha=0.7)\n",
    "    \n",
    "    plt.title('Feature Importance Comparison')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot feature importance\n",
    "feature_names = X_train.columns\n",
    "plot_feature_importance(models, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69a19824-d7fc-4035-b0d7-ddc50ccdb76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightgbm) (1.26.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightgbm) (1.13.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.3-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.26.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-2.1.3-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/124.9 MB 2.1 MB/s eta 0:01:00\n",
      "   ---------------------------------------- 1.3/124.9 MB 2.2 MB/s eta 0:00:56\n",
      "    --------------------------------------- 1.8/124.9 MB 2.2 MB/s eta 0:00:56\n",
      "    --------------------------------------- 2.6/124.9 MB 2.5 MB/s eta 0:00:50\n",
      "   - -------------------------------------- 3.1/124.9 MB 2.5 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 3.9/124.9 MB 2.7 MB/s eta 0:00:45\n",
      "   - -------------------------------------- 4.7/124.9 MB 2.8 MB/s eta 0:00:43\n",
      "   - -------------------------------------- 5.8/124.9 MB 3.0 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 6.8/124.9 MB 3.2 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 7.9/124.9 MB 3.4 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 8.9/124.9 MB 3.5 MB/s eta 0:00:33\n",
      "   --- ------------------------------------ 10.2/124.9 MB 3.7 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 11.5/124.9 MB 3.9 MB/s eta 0:00:29\n",
      "   ---- ----------------------------------- 13.1/124.9 MB 4.2 MB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 14.9/124.9 MB 4.4 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 16.5/124.9 MB 4.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 18.4/124.9 MB 4.8 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 19.4/124.9 MB 4.8 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 21.2/124.9 MB 5.0 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 23.9/124.9 MB 5.4 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 26.7/124.9 MB 5.8 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 29.6/124.9 MB 6.1 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 32.5/124.9 MB 6.4 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 35.9/124.9 MB 6.8 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 39.6/124.9 MB 7.2 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 42.5/124.9 MB 7.4 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 45.4/124.9 MB 7.7 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 48.0/124.9 MB 7.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 51.4/124.9 MB 8.1 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 54.8/124.9 MB 8.4 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 57.9/124.9 MB 8.6 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 60.0/124.9 MB 8.6 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 62.9/124.9 MB 8.8 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 67.6/124.9 MB 9.1 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 72.4/124.9 MB 9.5 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 76.8/124.9 MB 9.8 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 81.0/124.9 MB 10.1 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 86.2/124.9 MB 10.4 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 93.1/124.9 MB 11.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 97.5/124.9 MB 11.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 102.5/124.9 MB 11.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 105.6/124.9 MB 11.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 108.5/124.9 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 111.9/124.9 MB 11.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 118.0/124.9 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  122.7/124.9 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 12.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 124.9/124.9 MB 12.2 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "034c667c-3e63-4983-b7e1-ddf431f2049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "import requests\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import Dict, Tuple\n",
    "from shapely.geometry import Polygon, MultiPolygon, LineString\n",
    "from shapely.ops import unary_union\n",
    "import json\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e46efe27-de50-427e-ae88-17273e4530ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LightGBM': LGBMRegressor(feature_fraction=0.8, learning_rate=0.05, n_jobs=-1,\n",
       "               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.8),\n",
       " 'XGBoost': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=42, ...),\n",
       " 'CatBoost': <catboost.core.CatBoostRegressor at 0x1a214e53310>}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69ea4587-5399-43b4-8c6e-3158be55f57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03bb7c2f-f487-4194-9593-1a97304d5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models\n",
    "with open('models.pkl', 'rb') as f:\n",
    "    loaded_models = pickle.load(f)\n",
    "\n",
    "# Load the ensemble weights\n",
    "with open('ensemble_weights.pkl', 'rb') as f:\n",
    "    loaded_weights = pickle.load(f)\n",
    "\n",
    "# Load the label encoders and scaler\n",
    "with open('preprocessors.pkl', 'rb') as f:\n",
    "    loaded_label_encoders, loaded_scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c9a56112-1568-4cb4-a3f3-2fde945b8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {'latitude':11.96,\n",
    "        'longitude':75.92,\n",
    "        'use_case_type':'Agricultural'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b2a288a5-528e-46c9-84a5-3bbd8f1b0bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the models\n",
    "with open('models2.pkl', 'rb') as f:\n",
    "    loaded_models = pickle.load(f)\n",
    "\n",
    "# Save the ensemble predictions weights\n",
    "with open('ensemble_weights2.pkl', 'rb') as f:\n",
    "    loaded_weights = pickle.load(f)\n",
    "\n",
    "# Save the label encoders and scaler\n",
    "with open('preprocessors2.pkl', 'rb') as f:\n",
    "    loaded_encoders, loaded_scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a2bc0860-0943-4cdf-a9a5-bd084f509b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'land_use_type': LabelEncoder()}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "67b3c952-e035-4129-84f9-719b5aa6e474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Agricultural', 'Commercial', 'Eco-friendly', 'Residential'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_encoders['land_use_type'].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5581cafd-3c85-49c5-a400-fe96742db101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.46.0-cp311-cp311-win_amd64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (1.26.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (1.5.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (2.1.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (23.2)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting numba (from shap)\n",
      "  Downloading numba-0.60.0-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting cloudpickle (from shap)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->shap)\n",
      "  Downloading llvmlite-0.43.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->shap) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Downloading shap-0.46.0-cp311-cp311-win_amd64.whl (456 kB)\n",
      "Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading numba-0.60.0-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.43.0-cp311-cp311-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.6/28.1 MB 15.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 5.5/28.1 MB 14.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.9/28.1 MB 13.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 11.0/28.1 MB 13.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 14.2/28.1 MB 13.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 17.0/28.1 MB 14.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 20.4/28.1 MB 14.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.6/28.1 MB 14.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.0/28.1 MB 14.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 14.0 MB/s eta 0:00:00\n",
      "Installing collected packages: slicer, llvmlite, cloudpickle, numba, shap\n",
      "Successfully installed cloudpickle-3.1.1 llvmlite-0.43.0 numba-0.60.0 shap-0.46.0 slicer-0.0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c9d7e2ff-52e5-4e54-a99f-a205cda59186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 03:35:03,850 - INFO - Processing region 1/1: 11.96, 75.92\n",
      "2025-01-19 03:35:37,256 - ERROR - Error in primary green cover fetch: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "import requests\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import Dict, Tuple\n",
    "from shapely.geometry import Polygon, MultiPolygon, LineString\n",
    "from shapely.ops import unary_union\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from typing import Optional\n",
    "import json\n",
    "import shap\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#change this shit\n",
    "cache = {'latitude':11.96,\n",
    "        'longitude':75.92,\n",
    "        'use_case_type':'Agricultural'}\n",
    "\n",
    "with open('models2.pkl', 'rb') as f:\n",
    "    loaded_models = pickle.load(f)\n",
    "\n",
    "with open('ensemble_weights2.pkl', 'rb') as f:\n",
    "    loaded_weights = pickle.load(f)\n",
    "    \n",
    "with open('preprocessors2.pkl', 'rb') as f:\n",
    "    loaded_encoders, loaded_scaler = pickle.load(f)\n",
    "\n",
    "latitude = cache['latitude']\n",
    "longitude = cache['longitude']\n",
    "use_case_type = cache['use_case_type']\n",
    "\n",
    "def fetch_climate_data(lat: float, lon: float) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Fetch climate data using OpenWeatherMap API with 5-day precipitation forecast.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get current weather\n",
    "        current_url = f\"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
    "        current_response = requests.get(current_url)\n",
    "        current_response.raise_for_status()\n",
    "        current_data = current_response.json()\n",
    "        \n",
    "        # Get 5 day forecast with 3-hour steps\n",
    "        forecast_url = f\"https://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
    "        forecast_response = requests.get(forecast_url)\n",
    "        forecast_response.raise_for_status()\n",
    "        forecast_data = forecast_response.json()\n",
    "        \n",
    "        # Calculate average precipitation from forecast\n",
    "        total_precipitation = 0\n",
    "        count = 0\n",
    "        \n",
    "        for item in forecast_data.get('list', []):\n",
    "            # Get precipitation (rain or snow)\n",
    "            rain_amount = item.get('rain', {}).get('3h', 0)\n",
    "            snow_amount = item.get('snow', {}).get('3h', 0)\n",
    "            total_precipitation += rain_amount + snow_amount\n",
    "            count += 1\n",
    "        \n",
    "        # Convert 3-hourly precipitation to daily average\n",
    "        avg_daily_precipitation = (total_precipitation / count) * 8 if count > 0 else 0\n",
    "        # Estimate monthly precipitation (multiply by 30 days)\n",
    "        estimated_monthly_precipitation = avg_daily_precipitation * 30\n",
    "        \n",
    "        return {\n",
    "            \"temperature\": current_data[\"main\"][\"temp\"],\n",
    "            \"precipitation\": estimated_monthly_precipitation,\n",
    "            \"humidity\": current_data[\"main\"][\"humidity\"],\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching climate data for {lat}, {lon}: {str(e)}\")\n",
    "        return None\n",
    "    finally:\n",
    "        time.sleep(REQUEST_DELAY)\n",
    "\n",
    "def _get_overpass_data(query: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Helper function to fetch data from Overpass API.\n",
    "    \"\"\"\n",
    "    overpass_url = \"https://overpass-api.de/api/interpreter\"\n",
    "    try:\n",
    "        response = requests.post(overpass_url, data={'data': query})\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        # logger.error(f\"Overpass API error: {str(e)}\")\n",
    "        return {'elements': []}\n",
    "\n",
    "def fetch_land_usage_data(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fetch land usage data using Overpass API.\n",
    "    Returns urban density index between 0 and 1.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calculate bounding box (1km radius)\n",
    "        radius = 1000  # meters\n",
    "        deg_radius = radius / 111320  # Convert meters to degrees (approximate)\n",
    "        \n",
    "        # Overpass query for buildings and roads\n",
    "        query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          way[\"building\"](around:{radius},{lat},{lon});\n",
    "          way[\"highway\"](around:{radius},{lat},{lon});\n",
    "        );\n",
    "        out body geom;\n",
    "        \"\"\"\n",
    "        \n",
    "        data = _get_overpass_data(query)\n",
    "        \n",
    "        if not data['elements']:\n",
    "            # Fallback to secondary API\n",
    "            return _fetch_land_usage_fallback(lat, lon)\n",
    "        \n",
    "        # Calculate areas and lengths\n",
    "        total_area = np.pi * (radius ** 2)  # Total circular area in square meters\n",
    "        building_area = 0\n",
    "        road_length = 0\n",
    "        \n",
    "        for element in data['elements']:\n",
    "            if 'geometry' in element:\n",
    "                coords = [(p['lon'], p['lat']) for p in element['geometry']]\n",
    "                if element.get('tags', {}).get('building'):\n",
    "                    # Calculate building area\n",
    "                    if len(coords) >= 3:\n",
    "                        try:\n",
    "                            polygon = Polygon(coords)\n",
    "                            building_area += polygon.area * 111320 * 111320  # Convert to square meters\n",
    "                        except:\n",
    "                            continue\n",
    "                elif element.get('tags', {}).get('highway'):\n",
    "                    # Calculate road length\n",
    "                    if len(coords) >= 2:\n",
    "                        try:\n",
    "                            line = LineString(coords)\n",
    "                            road_length += line.length * 111320  # Convert to meters\n",
    "                        except:\n",
    "                            continue\n",
    "        \n",
    "        # Calculate urban density\n",
    "        building_density = min(building_area / total_area, 0.7)  # Cap at 70%\n",
    "        road_density = min(road_length / (radius * 2 * np.pi), 0.3)  # Cap at 30%\n",
    "        \n",
    "        urban_density = building_density + road_density\n",
    "        return min(max(urban_density, 0), 1)\n",
    "    \n",
    "    except Exception as e:\n",
    "        # logger.error(f\"Error in primary land usage calculation: {str(e)}\")\n",
    "        return _fetch_land_usage_fallback(lat, lon)\n",
    "\n",
    "def _fetch_land_usage_fallback(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fallback method using OpenStreetMap Nominatim API for land use data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use Nominatim API to get area details\n",
    "        nominatim_url = f\"https://nominatim.openstreetmap.org/reverse?lat={lat}&lon={lon}&format=json&zoom=14\"\n",
    "        headers = {'User-Agent': 'Urban Density Calculator 1.0'}\n",
    "        \n",
    "        response = requests.get(nominatim_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Analyze address components and category\n",
    "        address = data.get('address', {})\n",
    "        category = data.get('category', '')\n",
    "        \n",
    "        # Calculate urban density based on location type\n",
    "        if any(k in address for k in ['city', 'town', 'suburb']):\n",
    "            return 0.8  # Urban area\n",
    "        elif 'village' in address:\n",
    "            return 0.4  # Rural settlement\n",
    "        elif any(k in address for k in ['industrial', 'commercial']):\n",
    "            return 0.9  # Industrial/commercial area\n",
    "        elif any(k in address for k in ['forest', 'park', 'nature_reserve']):\n",
    "            return 0.1  # Natural area\n",
    "        else:\n",
    "            return 0.5  # Default semi-urban\n",
    "            \n",
    "    except Exception as e:\n",
    "        # logger.error(f\"Error in fallback land usage calculation: {str(e)}\")\n",
    "        return 0.5  # Default value\n",
    "\n",
    "def fetch_water_coverage_data(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fetch water coverage data using Overpass API.\n",
    "    Returns water coverage ratio between 0 and 1.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calculate bounding box (1km radius)\n",
    "        radius = 1000  # meters\n",
    "        \n",
    "        # Overpass query for water features\n",
    "        query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          way[\"natural\"=\"water\"](around:{radius},{lat},{lon});\n",
    "          way[\"waterway\"](around:{radius},{lat},{lon});\n",
    "          way[\"water\"](around:{radius},{lat},{lon});\n",
    "          way[\"natural\"=\"wetland\"](around:{radius},{lat},{lon});\n",
    "        );\n",
    "        out body geom;\n",
    "        \"\"\"\n",
    "        \n",
    "        data = _get_overpass_data(query)\n",
    "        \n",
    "        if not data['elements']:\n",
    "            # Fallback to secondary API\n",
    "            return _fetch_water_coverage_fallback(lat, lon)\n",
    "        \n",
    "        # Calculate areas\n",
    "        total_area = np.pi * (radius ** 2)  # Total circular area in square meters\n",
    "        water_area = 0\n",
    "        \n",
    "        for element in data['elements']:\n",
    "            if 'geometry' in element:\n",
    "                coords = [(p['lon'], p['lat']) for p in element['geometry']]\n",
    "                if len(coords) >= 3:\n",
    "                    try:\n",
    "                        polygon = Polygon(coords)\n",
    "                        water_area += polygon.area * 111320 * 111320  # Convert to square meters\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        water_coverage = water_area / total_area\n",
    "        return min(max(water_coverage, 0), 1)\n",
    "    \n",
    "    except Exception as e:\n",
    "        # logger.error(f\"Error in primary water coverage calculation: {str(e)}\")\n",
    "        return _fetch_water_coverage_fallback(lat, lon)\n",
    "\n",
    "def _fetch_water_coverage_fallback(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fallback method using OpenMeteo API for water proximity data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use OpenMeteo API for water-related data\n",
    "        url = f\"https://marine-api.open-meteo.com/v1/marine?latitude={lat}&longitude={lon}&daily=wave_height\"\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'daily' in data and 'wave_height' in data['daily']:\n",
    "            # If wave height data is available, location is near water\n",
    "            return min(max(np.mean(data['daily']['wave_height']) / 2, 0), 1)\n",
    "            \n",
    "        # If no marine data, check for inland water bodies using Nominatim\n",
    "        nominatim_url = f\"https://nominatim.openstreetmap.org/reverse?lat={lat}&lon={lon}&format=json&zoom=14\"\n",
    "        headers = {'User-Agent': 'Water Coverage Calculator 1.0'}\n",
    "        \n",
    "        response = requests.get(nominatim_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Check location type\n",
    "        if any(water_type in str(data).lower() for water_type in ['lake', 'river', 'sea', 'ocean', 'bay', 'wetland']):\n",
    "            return 0.7  # Significant water presence\n",
    "        return 0.1  # Minimal water presence\n",
    "            \n",
    "    except Exception as e:\n",
    "        # logger.error(f\"Error in fallback water coverage calculation: {str(e)}\")\n",
    "        return 0.1  # Default low water coverage\n",
    "\n",
    "def fetch_green_cover_data(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fetch green cover data using Copernicus Global Land Service API.\n",
    "    Uses NDVI (Normalized Difference Vegetation Index) data.\n",
    "    \n",
    "    Args:\n",
    "        lat (float): Latitude\n",
    "        lon (float): Longitude\n",
    "    \n",
    "    Returns:\n",
    "        float: NDVI value between 0 and 1\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Using Copernicus Global Land Service API\n",
    "        base_url = \"https://land.copernicus.vgt.vito.be/REST/TimeSeries/1.0/extract\"\n",
    "        \n",
    "        # Current date and one month ago\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=30)\n",
    "        \n",
    "        params = {\n",
    "            'lat': lat,\n",
    "            'lon': lon,\n",
    "            'startdate': start_date.strftime('%Y-%m-%d'),\n",
    "            'enddate': end_date.strftime('%Y-%m-%d'),\n",
    "            'collection': 'NDVI_V2',\n",
    "            'format': 'json'\n",
    "        }\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0',\n",
    "            'Accept': 'application/json'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(base_url, params=params, headers=headers)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            # Fallback to alternative API: OpenMeteo\n",
    "            return _fetch_green_cover_fallback(lat, lon)\n",
    "            \n",
    "        data = response.json()\n",
    "        ndvi_values = [item['NDVI'] for item in data['results'] if 'NDVI' in item]\n",
    "        \n",
    "        if ndvi_values:\n",
    "            # NDVI values are typically between -1 and 1\n",
    "            # Normalize to 0-1 range\n",
    "            avg_ndvi = np.mean(ndvi_values)\n",
    "            normalized_ndvi = (avg_ndvi + 1) / 2\n",
    "            return max(min(normalized_ndvi, 1), 0)\n",
    "            \n",
    "        return _fetch_green_cover_fallback(lat, lon)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in primary green cover fetch: {str(e)}\")\n",
    "        return _fetch_green_cover_fallback(lat, lon)\n",
    "\n",
    "def _fetch_green_cover_fallback(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Fallback method using OpenMeteo API for vegetation data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # OpenMeteo API for soil and vegetation data\n",
    "        url = (f\"https://api.open-meteo.com/v1/forecast?\"\n",
    "               f\"latitude={lat}&longitude={lon}\"\n",
    "               f\"&hourly=soil_moisture_0_1cm,soil_moisture_1_3cm\"\n",
    "               f\"&daily=et0_fao_evapotranspiration\")\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Calculate green cover proxy using soil moisture and evapotranspiration\n",
    "        soil_moisture = np.mean(data['hourly']['soil_moisture_0_1cm'][:24])  # First 24 hours\n",
    "        evapotranspiration = data['daily']['et0_fao_evapotranspiration'][0]  # First day\n",
    "        \n",
    "        # Combine metrics to estimate vegetation cover\n",
    "        # Normalize values based on typical ranges\n",
    "        soil_moisture_norm = min(soil_moisture / 50, 1)  # Typical range 0-50\n",
    "        evapotrans_norm = min(evapotranspiration / 10, 1)  # Typical range 0-10\n",
    "        \n",
    "        # Weight the factors\n",
    "        green_cover = (soil_moisture_norm * 0.6 + evapotrans_norm * 0.4)\n",
    "        \n",
    "        return max(min(green_cover, 1), 0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # logger.error(f\"Error in fallback green cover fetch: {str(e)}\")\n",
    "        return _fetch_green_cover_last_resort(lat, lon)\n",
    "\n",
    "def _fetch_green_cover_last_resort(lat: float, lon: float) -> float:\n",
    "    \"\"\"\n",
    "    Last resort method using NASA POWER API for vegetation-related data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # NASA POWER API\n",
    "        base_url = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "        \n",
    "        params = {\n",
    "            'parameters': 'T2M,PRECTOT,RH2M',  # Temperature, precipitation, humidity\n",
    "            'community': 'AG',\n",
    "            'longitude': lon,\n",
    "            'latitude': lat,\n",
    "            'start': datetime.now().strftime('%Y%m%d'),\n",
    "            'end': datetime.now().strftime('%Y%m%d'),\n",
    "            'format': 'JSON'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract relevant parameters\n",
    "        temp = float(data['properties']['parameter']['T2M'][datetime.now().strftime('%Y%m%d')])\n",
    "        precip = float(data['properties']['parameter']['PRECTOT'][datetime.now().strftime('%Y%m%d')])\n",
    "        humidity = float(data['properties']['parameter']['RH2M'][datetime.now().strftime('%Y%m%d')])\n",
    "        \n",
    "        # Create a simple vegetation index based on environmental conditions\n",
    "        # This is a rough approximation based on typical conditions favorable for vegetation\n",
    "        temp_factor = max(0, min(1 - abs(temp - 20) / 30, 1))  # Optimal temp around 20°C\n",
    "        precip_factor = min(precip / 10, 1)  # Normalize precipitation (0-10mm)\n",
    "        humidity_factor = humidity / 100  # Humidity is already 0-100\n",
    "        \n",
    "        # Combine factors with weights\n",
    "        green_cover = (temp_factor * 0.3 + precip_factor * 0.4 + humidity_factor * 0.3)\n",
    "        \n",
    "        return max(min(green_cover, 1), 0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # logger.error(f\"Error in last resort green cover fetch: {str(e)}\")\n",
    "        # Return a reasonable default based on global averages\n",
    "        return 0.3  # Global average vegetation cover is roughly 30%\n",
    "\n",
    "def fetch_biodiversity_data(lat: float, lon: float) -> int:\n",
    "    \"\"\"\n",
    "    Fetch biodiversity data using GBIF API with improved species counting.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        params = {\n",
    "            \"decimalLatitude\": f\"{lat-0.5},{lat+0.5}\",\n",
    "            \"decimalLongitude\": f\"{lon-0.5},{lon+0.5}\",\n",
    "            \"limit\": 300,  # Increased limit\n",
    "            \"hasCoordinate\": True,\n",
    "            \"hasGeospatialIssue\": False\n",
    "        }\n",
    "        response = requests.get(GBIF_API_BASE, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        time.sleep(REQUEST_DELAY)\n",
    "        \n",
    "        # Count unique species\n",
    "        species_set = set()\n",
    "        for record in data.get(\"results\", []):\n",
    "            if record.get(\"species\"):\n",
    "                species_set.add(record[\"species\"])\n",
    "        \n",
    "        return len(species_set)\n",
    "    except Exception as e:\n",
    "        # logger.error(f\"Error fetching biodiversity data for {lat}, {lon}: {str(e)}\")\n",
    "        return 0   \n",
    "\n",
    "def create_dataset(\n",
    "    cache):\n",
    "    \"\"\"\n",
    "    Create a labeled dataset across various regions with selected land use types.\n",
    "    \n",
    "    Args:\n",
    "        regions (list): List of dictionaries containing lat/lon coordinates\n",
    "        land_use_types (list): List of land use type strings\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataset containing environmental metrics and risk scores\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    regions = [{\"lat\": cache['latitude'], \"lon\": cache['longitude']}]\n",
    "    land_use_types = [cache['use_case_type']]\n",
    "    total_regions = len(regions)\n",
    "    \n",
    "    for idx, region in enumerate(regions, 1):\n",
    "        try:\n",
    "            lat, lon = region[\"lat\"], region[\"lon\"]\n",
    "            logger.info(f\"Processing region {idx}/{total_regions}: {lat}, {lon}\")\n",
    "            \n",
    "            climate_data = fetch_climate_data(lat, lon)\n",
    "            biodiversity_data = fetch_biodiversity_data(lat, lon)\n",
    "            green_cover = fetch_green_cover_data(lat, lon)\n",
    "            land_usage = fetch_land_usage_data(lat, lon)\n",
    "            water_coverage = fetch_water_coverage_data(lat, lon)\n",
    "            \n",
    "            if climate_data:\n",
    "                for land_use_type in land_use_types:\n",
    "                    \n",
    "                    data.append({\n",
    "                        \"latitude\": lat,\n",
    "                        \"longitude\": lon,\n",
    "                        \"temperature\": climate_data[\"temperature\"],\n",
    "                        \"precipitation\": climate_data[\"precipitation\"],\n",
    "                        \"humidity\": climate_data[\"humidity\"],\n",
    "                        \"species_richness\": biodiversity_data,\n",
    "                        \"ndvi\": green_cover,\n",
    "                        \"urban_land_usage\": land_usage,\n",
    "                        \"water_coverage\": water_coverage,\n",
    "                        \"land_use_type\": land_use_type,\n",
    "                        # \"timestamp\": datetime.now().isoformat()\n",
    "                    })\n",
    "            \n",
    "        except Exception as e:\n",
    "            # logger.error(f\"Error processing region {lat}, {lon}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def preprocess_inference_data(input_data, label_encoders, scaler):\n",
    "    \"\"\"\n",
    "    Preprocess input data for inference.\n",
    "    \n",
    "    Args:\n",
    "        input_data (pd.DataFrame): New input data for prediction.\n",
    "        label_encoders (dict): Dictionary of fitted LabelEncoders for categorical features.\n",
    "        scaler (StandardScaler): Fitted StandardScaler for numerical features.\n",
    "        categorical_columns (list): List of categorical feature names.\n",
    "        numerical_columns (list): List of numerical feature names.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed input data.\n",
    "    \"\"\"\n",
    "    data = input_data.copy()\n",
    "\n",
    "    categorical_columns = ['land_use_type']\n",
    "    numerical_columns = ['latitude', 'longitude', 'temperature', 'precipitation', \n",
    "                         'ndvi', 'urban_land_usage', 'water_coverage','humidity', 'species_richness']\n",
    "    \n",
    "    # Encode categorical features\n",
    "    for col in categorical_columns:\n",
    "        if col in data.columns and col in label_encoders:\n",
    "            data[col] = label_encoders[col].transform(data[col])\n",
    "    \n",
    "    # Scale numerical features\n",
    "    if set(numerical_columns).issubset(data.columns):\n",
    "        data[numerical_columns] = scaler.transform(data[numerical_columns])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def predict(input_data, models, weights, label_encoders, scaler):\n",
    "    \"\"\"\n",
    "    Perform inference on input data.\n",
    "    \n",
    "    Args:\n",
    "        input_data (pd.DataFrame): New input data for prediction.\n",
    "        models (dict): Dictionary of trained models.\n",
    "        weights (dict): Dictionary of model weights for ensemble.\n",
    "        label_encoders (dict): Fitted label encoders for categorical features.\n",
    "        scaler (StandardScaler): Fitted scaler for numerical features.\n",
    "        categorical_columns (list): List of categorical feature names.\n",
    "        numerical_columns (list): List of numerical feature names.\n",
    "    \n",
    "    Returns:\n",
    "        float: Final ensemble prediction for `risk_score`.\n",
    "    \"\"\"\n",
    "    # Preprocess the data\n",
    "    processed_data = preprocess_inference_data(input_data, label_encoders, scaler)\n",
    "    \n",
    "    # Generate predictions for each model\n",
    "    predictions = {\n",
    "        name: model.predict(processed_data) for name, model in models.items()\n",
    "    }\n",
    "    \n",
    "    # Compute weighted ensemble prediction\n",
    "    ensemble_prediction = sum(predictions[model] * weight for model, weight in weights.items())\n",
    "    return ensemble_prediction\n",
    "\n",
    "def calculate_shap_values(input_data: pd.DataFrame, models: dict, weights: dict, label_encoders: dict, scaler: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate SHAP values for the ensemble model predictions.\n",
    "    \n",
    "    Args:\n",
    "        input_data (pd.DataFrame): Input data for prediction\n",
    "        models (dict): Dictionary of trained models\n",
    "        weights (dict): Dictionary of model weights for ensemble\n",
    "        label_encoders (dict): Fitted label encoders for categorical features\n",
    "        scaler (dict): Fitted scaler for numerical features\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing SHAP values for each feature\n",
    "    \"\"\"\n",
    "    # Preprocess the data\n",
    "    processed_data = preprocess_inference_data(input_data, label_encoders, scaler)\n",
    "    \n",
    "    # Initialize SHAP values array\n",
    "    final_shap_values = np.zeros(processed_data.shape[1])\n",
    "    \n",
    "    # Calculate SHAP values for each model and apply ensemble weights\n",
    "    for model_name, model in models.items():\n",
    "        # Create explainer based on model type\n",
    "        if isinstance(model, LGBMRegressor):\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "        elif isinstance(model, XGBRegressor):\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "        elif isinstance(model, CatBoostRegressor):\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        # Calculate SHAP values for current model\n",
    "        shap_values = explainer.shap_values(processed_data)\n",
    "        \n",
    "        # If shap_values is a list (happens with some models), take the first element\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = shap_values[0]\n",
    "            \n",
    "        # Apply model weight to SHAP values\n",
    "        weighted_shap = shap_values * weights[model_name]\n",
    "        \n",
    "        # Add to final SHAP values\n",
    "        final_shap_values += weighted_shap[0]  # Take first row as we're only predicting for one instance\n",
    "    \n",
    "    # Create dictionary with feature names and their SHAP values\n",
    "    feature_names = ['latitude', 'longitude', 'temperature', 'precipitation', \n",
    "                    'humidity', 'species_richness', 'ndvi', 'urban_land_usage', \n",
    "                    'water_coverage', 'land_use_type']\n",
    "    \n",
    "    shap_dict = {\n",
    "        feature: float(shap_value)  # Convert numpy float to Python float for JSON serialization\n",
    "        for feature, shap_value in zip(feature_names, final_shap_values)\n",
    "    }\n",
    "    \n",
    "    # Sort dictionary by absolute SHAP values to show features in order of importance\n",
    "    shap_dict = dict(sorted(shap_dict.items(), key=lambda x: abs(x[1]), reverse=True))\n",
    "    \n",
    "    return {\n",
    "        \"shap_values\": shap_dict,\n",
    "        \"explanation\": {\n",
    "            \"positive_impact\": [k for k, v in shap_dict.items() if v > 0],\n",
    "            \"negative_impact\": [k for k, v in shap_dict.items() if v < 0],\n",
    "            \"most_influential_features\": list(shap_dict.keys())[:3]\n",
    "        }\n",
    "    }\n",
    "input_data = create_dataset(cache)\n",
    "risk_score_prediction = predict(\n",
    "        input_data=input_data,\n",
    "        models=loaded_models,\n",
    "        weights=loaded_weights,\n",
    "        label_encoders=loaded_encoders,\n",
    "        scaler=loaded_scaler\n",
    "    )\n",
    "\n",
    "shap_analysis = calculate_shap_values(\n",
    "    input_data=input_data,\n",
    "    models=loaded_models,\n",
    "    weights=loaded_weights,\n",
    "    label_encoders=loaded_encoders,\n",
    "    scaler=loaded_scaler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bcc7160b-3533-4a29-9fba-ab3b01c5d287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "2025-01-19 04:22:14,180 - INFO - Request URL: 'https://models.inference.ai.azure.com/chat/completions?api-version=REDACTED'\n",
      "Request method: 'POST'\n",
      "Request headers:\n",
      "    'Content-Type': 'application/json'\n",
      "    'Content-Length': '2370'\n",
      "    'Accept': 'application/json'\n",
      "    'x-ms-client-request-id': 'dc017502-d5ee-11ef-9098-401a583f997f'\n",
      "    'api-key': 'REDACTED'\n",
      "    'User-Agent': 'azsdk-python-ai-inference/1.0.0b7 Python/3.11.5 (Windows-10-10.0.22631-SP0)'\n",
      "    'Authorization': 'REDACTED'\n",
      "A body is sent with the request\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-inference in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.0b7)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-inference) (0.7.2)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-inference) (1.32.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-inference) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core>=1.30.0->azure-ai-inference) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core>=1.30.0->azure-ai-inference) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hs106\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 04:22:20,757 - INFO - Response status: 200\n",
      "Response headers:\n",
      "    'Date': 'Sat, 18 Jan 2025 22:52:22 GMT'\n",
      "    'Content-Type': 'application/json'\n",
      "    'Transfer-Encoding': 'chunked'\n",
      "    'Connection': 'keep-alive'\n",
      "    'Vary': 'REDACTED'\n",
      "    'x-ms-client-request-id': 'dc017502-d5ee-11ef-9098-401a583f997f'\n",
      "    'request-context': 'REDACTED'\n",
      "    'apim-request-id': 'REDACTED'\n",
      "    'strict-transport-security': 'REDACTED'\n",
      "    'x-content-type-options': 'REDACTED'\n",
      "    'x-ms-rai-invoked': 'REDACTED'\n",
      "    'x-request-id': 'REDACTED'\n",
      "    'x-ms-region': 'REDACTED'\n",
      "    'x-ratelimit-remaining-requests': 'REDACTED'\n",
      "    'x-ratelimit-remaining-tokens': 'REDACTED'\n",
      "    'azureml-model-session': 'REDACTED'\n",
      "    'x-aml-cluster': 'REDACTED'\n",
      "    'x-request-time': 'REDACTED'\n",
      "    'Content-Encoding': 'REDACTED'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Risk Analysis Summary\n",
      "The biodiversity risk score of 0.38 indicates a medium risk level for the specified agricultural region. Factors contributing to this score include the potential loss of habitat due to agricultural expansion, the presence of invasive species, and the fragmentation of natural landscapes. Urban development pressures and monoculture practices intensify these risks, making it imperative to manage biodiversity proactively in this region.\n",
      "\n",
      "### SHAP Impact Insights\n",
      "1. **Land Use Change (SHAP Feature 1)**:\n",
      "   - **Impact**: Significant contributor to biodiversity loss due to conversion of natural habitats into agricultural fields. \n",
      "   - **Quantification**: The model indicates a contribution to the risk score of approximately 0.15, marking it as the most impactful feature.\n",
      "   \n",
      "2. **Invasive Species Presence (SHAP Feature 2)**:\n",
      "   - **Impact**: Invasive species can outcompete native flora and fauna, drastically reducing local biodiversity.\n",
      "   - **Quantification**: This feature influences the risk score by around 0.10.\n",
      "   \n",
      "3. **Fragmentation of Habitats (SHAP Feature 3)**:\n",
      "   - **Impact**: Fragmentation reduces the area available for species, affecting wildlife movement and breeding.\n",
      "   - **Quantification**: Contributes approximately 0.08 to the risk score, significantly impacting ecosystem dynamics.\n",
      "\n",
      "**Interactions**: The interaction between land use change and habitat fragmentation results in compounded biodiversity loss, creating isolated patches that hinder species migration and genetic diversity.\n",
      "\n",
      "### Actionable Recommendations\n",
      "1. **Urban Planning Solutions**:\n",
      "   - Integrate biodiversity-friendly designs in agricultural development plans to maintain habitat integrity.\n",
      "   - Establish policies that prioritize the preservation of critical habitats amidst agricultural expansion.\n",
      "\n",
      "2. **Green Corridor Placement**: \n",
      "   - Design green corridors to connect fragmented habitats, using riverbanks and existing road buffers as natural pathways for wildlife.\n",
      "   - Implement planting buffers around agricultural fields, enabling movement and reducing edge effects.\n",
      "\n",
      "3. **Native Vegetation Preservation**:\n",
      "   - Encourage the preservation of native vegetative cover in agricultural practices, emphasizing agroforestry and intercropping systems.\n",
      "   - Implement incentive programs for farmers who maintain patches of native vegetation to enhance local biodiversity.\n",
      "\n",
      "### Implementation and Monitoring\n",
      "1. **Prioritization of Actions**:\n",
      "   - Immediate focus on mitigating land use change impacts (highest SHAP score) by enforcing land designations for conservation.\n",
      "   - Next, develop strategies to control invasive species and promote habitat connectivity before addressing fragmentation.\n",
      "\n",
      "2. **Phased Strategies**:\n",
      "   - **Phase 1**: Assessment of current land use and identification of critical habitats for preservation.\n",
      "   - **Phase 2**: Design and implement green corridors with collaboration from local stakeholders, including farmers.\n",
      "   - **Phase 3**: Launch native vegetation preservation initiatives and educational programs for farmers about biodiversity-friendly practices.\n",
      "\n",
      "3. **Monitoring Guidelines**:\n",
      "   - Establish baseline biodiversity metrics prior to changes (e.g., species count, habitat quality).\n",
      "   - Regularly monitor ecological health using indicators like species diversity and the extent of native vegetation cover post-implementation.\n",
      "   - Adapt strategies based on monitoring data, using a feedback loop to enhance biodiversity efforts.\n",
      "\n",
      "By addressing the identified risk factors comprehensively, these recommendations aim to lower the biodiversity risk score and enhance ecological resilience in this agricultural region.\n"
     ]
    }
   ],
   "source": [
    "# !pip install azure-ai-inference\n",
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage\n",
    "from azure.ai.inference.models import UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "def generate(system_prompt,ques):\n",
    "    client = ChatCompletionsClient(\n",
    "        endpoint=\"https://models.inference.ai.azure.com\",\n",
    "        credential=AzureKeyCredential('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'),\n",
    "    )\n",
    "    \n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            SystemMessage(content=system_prompt),\n",
    "            UserMessage(content=ques),\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=1,\n",
    "        max_tokens=4096,\n",
    "        top_p=1\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "SHAP = shap_analysis\n",
    "risk_score = risk_score_prediction\n",
    "\n",
    "def get_risk_level(score):\n",
    "        if score <= 0.3:\n",
    "            return \"Low\"\n",
    "        elif score <= 0.6:\n",
    "            return \"Medium\"\n",
    "        else:\n",
    "            return \"High\"\n",
    "    \n",
    "def get_priority_recommendations(shap_values, risk_level):\n",
    "    recommendations = []\n",
    "    key_factors = list(shap_values.items())\n",
    "    \n",
    "    # Urban density recommendations\n",
    "    if \"urban_land_usage\" in shap_values:\n",
    "        if shap_values[\"urban_land_usage\"] > 0:\n",
    "            recommendations.append({\n",
    "                \"category\": \"Urban Planning\",\n",
    "                \"impact\": \"High urban density is increasing biodiversity risk\",\n",
    "                \"solutions\": [\n",
    "                    \"Implement vertical gardens and green facades\",\n",
    "                    \"Create pocket parks in dense areas\",\n",
    "                    \"Establish green corridors connecting existing natural spaces\",\n",
    "                    \"Incorporate biodiversity-friendly infrastructure in new developments\"\n",
    "                ]\n",
    "            })\n",
    "    \n",
    "    # Green cover recommendations\n",
    "    if \"ndvi\" in shap_values:\n",
    "        if shap_values[\"ndvi\"] < 0:\n",
    "            recommendations.append({\n",
    "                \"category\": \"Vegetation\",\n",
    "                \"impact\": \"Low vegetation cover is affecting biodiversity\",\n",
    "                \"solutions\": [\n",
    "                    \"Preserve existing native vegetation\",\n",
    "                    \"Create urban forests with native species\",\n",
    "                    \"Implement green roof policies\",\n",
    "                    \"Develop urban wildlife corridors\"\n",
    "                ]\n",
    "            })\n",
    "    \n",
    "    # Water management recommendations\n",
    "    if \"water_coverage\" in shap_values:\n",
    "        if shap_values[\"water_coverage\"] < 0:\n",
    "            recommendations.append({\n",
    "                \"category\": \"Water Management\",\n",
    "                \"impact\": \"Limited water features affecting biodiversity\",\n",
    "                \"solutions\": [\n",
    "                    \"Create or restore wetland areas\",\n",
    "                    \"Implement sustainable urban drainage systems\",\n",
    "                    \"Develop blue corridors alongside green spaces\",\n",
    "                    \"Protect and enhance existing water bodies\"\n",
    "                ]\n",
    "            })\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "formatted_risk_score = float(risk_score) if hasattr(risk_score, 'item') else risk_score\n",
    "\n",
    "# Format SHAP values for display\n",
    "formatted_shap = json.dumps(shap_analysis['shap_values'], indent=2)\n",
    "\n",
    "# Format location data\n",
    "location_str = f\"Latitude: {cache['latitude']}, Longitude: {cache['longitude']}\"\n",
    "        \n",
    "system_prompt = f\"\"\"\n",
    "You are an expert assistant in biodiversity and urban planning specializing in SHAP-based impact assessments. Your task is to analyze impact predictions, reason about key contributing factors, and provide actionable recommendations for minimizing biodiversity loss in urban areas.\n",
    "\n",
    "Analysis Structure\n",
    "Reasoning for Risk Score:\n",
    "\n",
    "Explain the primary factors contributing to the risk score.\n",
    "Quantify the impact of the top three SHAP features and their significance.\n",
    "Highlight interaction effects among features influencing biodiversity.\n",
    "Targeted Recommendations:\n",
    "\n",
    "Urban Planning: Propose infrastructure changes like optimal green corridors, biodiversity-friendly designs, and urban density adjustments.\n",
    "Vegetation Management: Suggest preserving or planting native vegetation and improving habitat connectivity.\n",
    "Water Management: Recommend blue-green infrastructure to restore and maintain ecological balance.\n",
    "Implementation Guidelines:\n",
    "\n",
    "Prioritize changes based on SHAP feature impact.\n",
    "Address feasibility for the specific location, considering constraints and opportunities.\n",
    "Suggest phased implementation and monitoring metrics.\n",
    "Quality Requirements\n",
    "Ground all suggestions in SHAP-based numerical evidence.\n",
    "Ensure solutions align with the location’s risk level and context.\n",
    "Deliver a concise summary of reasoning and recommendations.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = f\"\"\"\"\n",
    "Biodiversity Risk Assessment\n",
    "\n",
    "Score: {formatted_risk_score:.2f} ({get_risk_level(risk_score)})\n",
    "Location: Latitude: {cache['latitude']}, Longitude: {cache['longitude']}\n",
    "Use Case: {cache['use_case_type']}\n",
    "Request:\n",
    "Please analyze the risk factors and provide a concise summary of:\n",
    "\n",
    "Reasoning:\n",
    "\n",
    "Why does the region have this risk score?\n",
    "What are the top three influential SHAP features, their impacts, and interactions?\n",
    "Recommendations:\n",
    "\n",
    "Urban planning solutions for minimizing biodiversity loss.\n",
    "Suggestions for green corridor placement and connectivity.\n",
    "Proposals for native vegetation preservation and biodiversity-friendly infrastructure.\n",
    "Implementation Plan:\n",
    "\n",
    "Prioritize actions based on SHAP impacts.\n",
    "Provide phased strategies and monitoring guidelines.\n",
    "Deliver your response in the following structure:\n",
    "\n",
    "Risk Analysis Summary\n",
    "SHAP Impact Insights\n",
    "Actionable Recommendations\n",
    "Implementation and Monitoring\n",
    "\"\"\"\n",
    "\n",
    "res = generate(system_prompt,user_prompt)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e59cbb53-53d8-4618-b6b4-c46d12c68d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38175822])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_score_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6e798a18-eb52-44f8-a8a8-a63f77914c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shap_values': {'land_use_type': -0.0448152283278025,\n",
       "  'temperature': -0.018244000393543854,\n",
       "  'longitude': -0.013338526311123469,\n",
       "  'water_coverage': 0.0026838123618429287,\n",
       "  'latitude': -0.0024881404592925088,\n",
       "  'ndvi': -0.0021252582829121088,\n",
       "  'urban_land_usage': -0.0009733150222182587,\n",
       "  'humidity': 0.0008662264032009992,\n",
       "  'precipitation': -0.0004439142014124292,\n",
       "  'species_richness': -4.1867731471293744e-05},\n",
       " 'explanation': {'positive_impact': ['water_coverage', 'humidity'],\n",
       "  'negative_impact': ['land_use_type',\n",
       "   'temperature',\n",
       "   'longitude',\n",
       "   'latitude',\n",
       "   'ndvi',\n",
       "   'urban_land_usage',\n",
       "   'precipitation',\n",
       "   'species_richness'],\n",
       "  'most_influential_features': ['land_use_type', 'temperature', 'longitude']}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4f62a90-15e8-48ba-a67e-440e1a2e5196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 02:46:51,144 - INFO - Processing region 1/1: 11.96, 75.92\n",
      "2025-01-19 02:47:24,004 - ERROR - Error in primary green cover fetch: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([{'latitude': 11.96, 'longitude': 75.92, 'temperature': 16.79, 'precipitation': 23.52, 'humidity': 85, 'species_richness': 206, 'ndvi': 0.187446, 'urban_land_usage': 0.5, 'water_coverage': 0.13021229656277938, 'land_use_type': 'Agricultural'}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions = [\n",
    "    {\"lat\": 10.7449, \"lon\": 92.5000},  # New York City, USA\n",
    "]\n",
    "# Define possible land use types\n",
    "land_use_types = [\n",
    "    \"green-based use\",\n",
    "]\n",
    "dataset = create_dataset(cache)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b8f80c-e154-4e67-bb6f-199fc79568e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inference_data(input_data, label_encoders, scaler, categorical_columns, numerical_columns):\n",
    "    \"\"\"\n",
    "    Preprocess input data for inference.\n",
    "    \n",
    "    Args:\n",
    "        input_data (pd.DataFrame): New input data for prediction.\n",
    "        label_encoders (dict): Dictionary of fitted LabelEncoders for categorical features.\n",
    "        scaler (StandardScaler): Fitted StandardScaler for numerical features.\n",
    "        categorical_columns (list): List of categorical feature names.\n",
    "        numerical_columns (list): List of numerical feature names.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed input data.\n",
    "    \"\"\"\n",
    "    data = input_data.copy()\n",
    "    \n",
    "    # Encode categorical features\n",
    "    for col in categorical_columns:\n",
    "        if col in data.columns and col in label_encoders:\n",
    "            data[col] = label_encoders[col].transform(data[col])\n",
    "    \n",
    "    # Scale numerical features\n",
    "    if set(numerical_columns).issubset(data.columns):\n",
    "        data[numerical_columns] = scaler.transform(data[numerical_columns])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def predict(input_data, models, weights, label_encoders, scaler, categorical_columns, numerical_columns):\n",
    "    \"\"\"\n",
    "    Perform inference on input data.\n",
    "    \n",
    "    Args:\n",
    "        input_data (pd.DataFrame): New input data for prediction.\n",
    "        models (dict): Dictionary of trained models.\n",
    "        weights (dict): Dictionary of model weights for ensemble.\n",
    "        label_encoders (dict): Fitted label encoders for categorical features.\n",
    "        scaler (StandardScaler): Fitted scaler for numerical features.\n",
    "        categorical_columns (list): List of categorical feature names.\n",
    "        numerical_columns (list): List of numerical feature names.\n",
    "    \n",
    "    Returns:\n",
    "        float: Final ensemble prediction for `risk_score`.\n",
    "    \"\"\"\n",
    "    # Preprocess the data\n",
    "    processed_data = preprocess_inference_data(input_data, label_encoders, scaler, categorical_columns, numerical_columns)\n",
    "    \n",
    "    # Generate predictions for each model\n",
    "    predictions = {\n",
    "        name: model.predict(processed_data) for name, model in models.items()\n",
    "    }\n",
    "    \n",
    "    # Compute weighted ensemble prediction\n",
    "    ensemble_prediction = sum(predictions[model] * weight for model, weight in weights.items())\n",
    "    return ensemble_prediction\n",
    "\n",
    "# Example Inference\n",
    "if __name__ == \"__main__\":\n",
    "    # Example input data\n",
    "    input_data = pd.DataFrame({\n",
    "        \"latitude\": [34.0522],\n",
    "        \"longitude\": [-118.2437],\n",
    "        \"temperature\": [25],\n",
    "        \"precipitation\": [50],\n",
    "        \"humidity\": [\"moderate\"],\n",
    "        \"ndvi\": [0.6],\n",
    "        \"species_richness\": [\"medium\"],\n",
    "        \"urban_land_usage\": [0.7],\n",
    "        \"water_coverage\": [0.3],\n",
    "        \"land_use_type\": [\"urban home-type use\"]\n",
    "    })\n",
    "    \n",
    "    # Define categorical and numerical columns\n",
    "    categorical_columns = ['humidity', 'species_richness', 'land_use_type']\n",
    "    numerical_columns = ['latitude', 'longitude', 'temperature', 'precipitation', \n",
    "                         'ndvi', 'urban_land_usage', 'water_coverage']\n",
    "    \n",
    "    # Perform inference\n",
    "    risk_score_prediction = predict(\n",
    "        input_data=input_data,\n",
    "        models=loaded_models,\n",
    "        weights=loaded_weights,\n",
    "        label_encoders=loaded_label_encoders,\n",
    "        scaler=loaded_scaler,\n",
    "        categorical_columns=categorical_columns,\n",
    "        numerical_columns=numerical_columns\n",
    "    )\n",
    "    \n",
    "    print(f\"Predicted Risk Score: {risk_score_prediction}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
